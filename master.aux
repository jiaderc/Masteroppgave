\relax 
\providecommand \oddpage@label [2]{}
\select@language{USenglish}
\@writefile{toc}{\select@language{USenglish}}
\@writefile{lof}{\select@language{USenglish}}
\@writefile{lot}{\select@language{USenglish}}
\citation{OptoforceFig}
\citation{OptoforceSheet}
\citation{Guyon2006}
\citation{MLP}
\citation{Cortes1995}
\citation{KnnClassification}
\citation{Quinlan1986}
\citation{Guyon2006}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{littleDog}
\citation{4651026}
\citation{6784609}
\citation{Dutta2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Outline}{2}}
\@writefile{toc}{\contentsline {paragraph}{Chapter 1: Introduction}{2}}
\@writefile{toc}{\contentsline {paragraph}{Chapter 2: Background}{2}}
\@writefile{toc}{\contentsline {paragraph}{Chapter 3: Implementation}{2}}
\@writefile{toc}{\contentsline {paragraph}{Chapter 4: Conclusion}{2}}
\citation{6569179}
\citation{Giguere06environmentidentification}
\citation{7487541}
\citation{6569179}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Terrain classification}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Types of legged robots}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Terrain classification for legged robots}{3}}
\citation{littleDog}
\citation{7487544}
\citation{5602459}
\citation{5509309}
\citation{Giguere2009}
\citation{6386243}
\citation{6569179}
\citation{6569179}
\citation{4399500}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Terrain sensing}{4}}
\@writefile{toc}{\contentsline {paragraph}{Remote sensing}{4}}
\@writefile{toc}{\contentsline {paragraph}{Local sensing}{4}}
\citation{6027100}
\citation{6907805}
\citation{Optoforce}
\citation{OptoforceFig}
\citation{OptoforceFig}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Optical force sensor}{5}}
\citation{Optoforce2}
\citation{7803326}
\citation{7759112}
\citation{7849467}
\citation{OptoforceSheet}
\citation{OptoforceSheet}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Figure showing construction of the 3d optical force used in thesis \cite  {OptoforceFig}\relax }}{6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:OptoforceBuild}{{2.1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Figure showing the x,y and z-direction for the 3d optical force used in this thesis \cite  {OptoforceSheet}.\relax }}{6}}
\newlabel{fig:OptoforceAxis}{{2.2}{6}}
\citation{6784609}
\citation{5752869}
\citation{4654717}
\citation{5152327}
\citation{6849778}
\citation{5602459}
\citation{4161556}
\citation{4059113}
\citation{6849778}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Machine learning}{7}}
\@writefile{toc}{\contentsline {paragraph}{Supervised learning}{7}}
\@writefile{toc}{\contentsline {paragraph}{Unsupervised learning}{7}}
\@writefile{toc}{\contentsline {paragraph}{Reinforcement learning}{7}}
\@writefile{toc}{\contentsline {paragraph}{Evolutionary learning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Classifier}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Neural network}{7}}
\citation{Guyon2006}
\citation{Guyon2006}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Figure showing The three principal approaches of feature selection. The shades show the components used by the three approaches: filters, wrappers and embedded methods \cite  {Guyon2006}\relax }}{8}}
\newlabel{fig:NN}{{2.3}{8}}
\@writefile{toc}{\contentsline {paragraph}{Multi-Layer Perceptron}{8}}
\citation{MLP}
\citation{MLP}
\citation{Cortes1995}
\citation{Cortes1995}
\citation{Cortes1995}
\citation{6225128}
\citation{5981563}
\citation{Giguere06environmentidentification}
\citation{6225128}
\citation{6225128}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Figure showing a multi-layer perceptron with 1 hidden layer \cite  {MLP}. It is possible to increase the number of hidden layers and nodes to each layer\relax }}{9}}
\newlabel{fig:MLP}{{2.4}{9}}
\@writefile{toc}{\contentsline {subsubsection}{SVM}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Naive bayes}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Figure showing an example of the optimal margin for a two dimensional two-class classification problem \cite  {Cortes1995}. Each of features vector with values according to the x- and y-axis, represents as classes: circles and crosses. The vectors with values according to the x- and y-axis. The support vectors are the hatced classes which lies on the straight line. "The dotted line is the decision boundary/hyperplane created by the SVM".\relax }}{10}}
\newlabel{fig:SVM}{{2.5}{10}}
\newlabel{eq:bayesNaivews}{{2.1}{10}}
\newlabel{eq:decision}{{2.2}{10}}
\citation{1053964}
\citation{KnnClassification}
\citation{KnnClassification}
\citation{Bao2004}
\citation{Quinlan1986}
\newlabel{eq:bayesLast}{{2.3}{11}}
\@writefile{toc}{\contentsline {subsubsection}{K-nearest neighbors }{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Figure showing an example of a KNN\cite  {KnnClassification}. All the blue squares and red triangles are the training data, while the green circle is to be classified. The straight and dashed circle illustrate which data set is taken account when k is set either 3 or 5. If k set to 3, the circle will be classified as triangle, since the tree nearest neighbor consist more triangles than squares. If k set to 5, then the cicle will be classified as square.\relax }}{11}}
\newlabel{fig:KNN}{{2.6}{11}}
\newlabel{eq:edistance}{{2.4}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Decision tree}{11}}
\citation{Quinlan1986}
\citation{Quinlan1986}
\citation{5602459}
\citation{5152662}
\citation{Giguere2009}
\citation{5509309}
\citation{4543710}
\citation{5979766}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Figure showing an example of a simple decision tree \cite  {Quinlan1986}. This decision tree classify a day to be P or N based on outlook, humidity and windy.\relax }}{12}}
\newlabel{fig:SVM}{{2.7}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Features}{12}}
\newlabel{features}{{2.4}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Curse of dimensionality}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Features extraction}{12}}
\newlabel{feature_extraction}{{2.4.2}{12}}
\citation{Press:2007:NRE:1403886}
\@writefile{toc}{\contentsline {subsubsection}{Statistical features}{13}}
\@writefile{toc}{\contentsline {paragraph}{Mean}{13}}
\newlabel{eq:mean}{{2.5}{13}}
\@writefile{toc}{\contentsline {paragraph}{Variance}{13}}
\newlabel{eq:variance}{{2.6}{13}}
\@writefile{toc}{\contentsline {paragraph}{Standard deviation}{13}}
\newlabel{eq:std}{{2.7}{13}}
\@writefile{toc}{\contentsline {paragraph}{Skewness}{13}}
\newlabel{eq:skew}{{2.8}{13}}
\citation{Guyon2006}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Skewness\relax }}{14}}
\newlabel{fig:skew}{{2.8}{14}}
\@writefile{toc}{\contentsline {paragraph}{Kurtosis}{14}}
\newlabel{eq:kurtosis}{{2.9}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Kurtosis\relax }}{14}}
\newlabel{fig:kurtosis}{{2.9}{14}}
\@writefile{toc}{\contentsline {paragraph}{Time domain}{14}}
\@writefile{toc}{\contentsline {paragraph}{Fourier transform}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Features selection}{14}}
\newlabel{selection}{{2.4.3}{14}}
\citation{Guyon2006}
\citation{Guyon2006}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces The figure showing the three principal approaches of feature selection. The shades show the components used by the three approaches: filters, wrappers and embedded methods. \cite  {Guyon2006}.\relax }}{15}}
\newlabel{fig:fitting}{{2.10}{15}}
\@writefile{toc}{\contentsline {paragraph}{Filter}{15}}
\@writefile{toc}{\contentsline {paragraph}{Wrapper}{15}}
\citation{NOFREELUNCH}
\citation{DBLP:conf/emcr/WeissFSZ07}
\citation{6849778}
\@writefile{toc}{\contentsline {paragraph}{Embedded}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Features scaling}{16}}
\newlabel{subsec:scaling}{{2.4.4}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Model validation}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}No free lunch theorem}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Ovefitting and underfitting}{16}}
\citation{6784609}
\citation{6386243}
\citation{Hoffmann20141790}
\citation{6849778}
\citation{7387710}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces The figure showing an example when the classifier is underfitted, overfitted or optimal.\relax }}{17}}
\newlabel{fig:fitting}{{2.11}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Cross-Validation}{17}}
\@writefile{toc}{\contentsline {paragraph}{K-fold}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Evaluating Classifiers}{17}}
\newlabel{subsec:evalclf}{{2.5.4}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces The figure showing an instance of k-fold cross valdiation. This is when k=n\relax }}{18}}
\newlabel{fig:kfold}{{2.12}{18}}
\@writefile{toc}{\contentsline {paragraph}{Precision}{18}}
\newlabel{eq:prec}{{2.10}{18}}
\@writefile{toc}{\contentsline {paragraph}{Accuracy}{18}}
\newlabel{eq:acc}{{2.11}{18}}
\@writefile{toc}{\contentsline {paragraph}{Recall}{18}}
\newlabel{eq:recall}{{2.12}{18}}
\@writefile{toc}{\contentsline {paragraph}{F-score}{18}}
\newlabel{eq:fscore}{{2.13}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces A confusion matrix of 3-class classification.\relax }}{19}}
\newlabel{tab:cmatrix}{{2.1}{19}}
\citation{scikit-learn}
\citation{runstats}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementation}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Implementation environment and language}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Python}{21}}
\@writefile{toc}{\contentsline {paragraph}{Scikit-learn}{21}}
\@writefile{toc}{\contentsline {paragraph}{Runstats}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Robot}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Figure showing dyret used in this project\relax }}{22}}
\newlabel{fig:robot}{{3.1}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Terrain}{22}}
\citation{optoRos}
\newlabel{fig:mean and std of net14}{{3.2a}{23}}
\newlabel{sub@fig:mean and std of net14}{{a}{23}}
\newlabel{fig:mean and std of net24}{{3.2b}{23}}
\newlabel{sub@fig:mean and std of net24}{{b}{23}}
\newlabel{fig:mean and std of net34}{{3.2c}{23}}
\newlabel{sub@fig:mean and std of net34}{{c}{23}}
\newlabel{fig:mean and std of net44}{{3.2d}{23}}
\newlabel{sub@fig:mean and std of net44}{{d}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces  }}{23}}
\newlabel{fig:terrains}{{3.2}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Data from optoforce sensor}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Segmentation of data}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Analyzing data from sensor}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Figure showing \texttt  {rqt\_plot} of a testrun on the floor.\relax }}{24}}
\newlabel{fig:graphf}{{3.3}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Figure showing \texttt  {rqt\_plot} of a testrun on the carpet terrain.\relax }}{25}}
\newlabel{fig:grapht}{{3.4}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Figure showing \texttt  {rqt\_plot} of a testrun on the hard mat terrain.\relax }}{25}}
\newlabel{fig:graphhm}{{3.5}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Figure showing \texttt  {rqt\_plot} of a testrun on the soft mat.\relax }}{25}}
\newlabel{fig:graphmm}{{3.6}{25}}
\newlabel{fig:sub1}{{3.7a}{26}}
\newlabel{sub@fig:sub1}{{a}{26}}
\newlabel{fig:sub2}{{3.7b}{26}}
\newlabel{sub@fig:sub2}{{b}{26}}
\newlabel{fig:sub3}{{3.7c}{26}}
\newlabel{sub@fig:sub3}{{c}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Figur showing the mean\relax }}{26}}
\newlabel{fig:meanx}{{3.7}{26}}
\newlabel{fig:sub1}{{3.8a}{27}}
\newlabel{sub@fig:sub1}{{a}{27}}
\newlabel{fig:sub2}{{3.8b}{27}}
\newlabel{sub@fig:sub2}{{b}{27}}
\newlabel{fig:sub3}{{3.8c}{27}}
\newlabel{sub@fig:sub3}{{c}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces FFT of \relax }}{27}}
\newlabel{fig:fft}{{3.8}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Feature extraction}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Time domain}{27}}
\@writefile{toc}{\contentsline {paragraph}{Feature set one - raw data}{27}}
\citation{Hoffmann20141790}
\newlabel{eq:f1}{{3.1}{28}}
\@writefile{toc}{\contentsline {paragraph}{Feature set two - statistical features}{28}}
\@writefile{toc}{\contentsline {subsubsection}{Frequency domain}{28}}
\@writefile{toc}{\contentsline {paragraph}{Feature set three - complete frequency spectrum}{28}}
\newlabel{eq:f2}{{3.3}{28}}
\@writefile{toc}{\contentsline {paragraph}{Feature set four - staticial features}{28}}
\@writefile{toc}{\contentsline {paragraph}{Feature set five - set two and four}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Tuning Parameters}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Learning approach}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The figure showing steps \relax }}{30}}
\newlabel{fig:M1}{{3.9}{30}}
\@writefile{toc}{\contentsline {subsubsection}{Details of the learning process}{30}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments and results}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Results of classifier}{33}}
\newlabel{result_exp1}{{4.1}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces My caption\relax }}{34}}
\newlabel{exp1}{{4.1}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Analysis}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Further improving all classifier}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The figure showing steps \relax }}{36}}
\newlabel{fig:M1}{{4.1}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Experiment 2 - classifier improvement}{36}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces My caption\relax }}{37}}
\newlabel{exp2}{{4.2}{37}}
\citation{hexapod}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Analysis}{38}}
\newlabel{exp2}{{4.4}{38}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Cross validation with unseen data}{38}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Dette er SVM wrapper feature set 2 fft\relax }}{39}}
\newlabel{svm1}{{4.3}{39}}
\@writefile{toc}{\contentsline {subsubsection}{SVM - Wrapper - Feature set two}{39}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Neural Network - Feature set 1 without selection\relax }}{40}}
\newlabel{nn2}{{4.4}{40}}
\@writefile{toc}{\contentsline {subsubsection}{Neuarl Network - Feature set one}{40}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Decision tree feature set 1 without filter\relax }}{41}}
\newlabel{dt3}{{4.5}{41}}
\@writefile{toc}{\contentsline {subsubsection}{Decision Tree - Feature set one}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces decision tree featureset 1 filter \relax }}{42}}
\newlabel{dt4}{{4.6}{42}}
\@writefile{toc}{\contentsline {subsubsection}{Decision Tree - Filter - Feature set one}{42}}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\citation{OptoforceFig}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Classification in real-time}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Figure showing an the optofoce used in this thesis \cite  {OptoforceFig}\relax }}{43}}
\newlabel{fig:optoforce}{{4.2}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Gulvet4teppe\relax }}{43}}
\newlabel{my-label}{{4.7}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Figure showing an the optofoce used in this thesis \cite  {OptoforceFig}\relax }}{44}}
\newlabel{fig:optoforce}{{4.3}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Hard matte 3 myk matte\relax }}{44}}
\newlabel{my-label}{{4.8}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Figure showing an the optoforce used in this thesis \cite  {OptoforceFig}\relax }}{44}}
\newlabel{fig:optoforce}{{4.4}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces MM 4Resten MBNY\relax }}{44}}
\newlabel{my-label}{{4.9}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Figure showing an the optofoce used in this thesis \cite  {OptoforceFig}\relax }}{45}}
\newlabel{fig:optoforce}{{4.5}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces MM4 Teppe\relax }}{45}}
\newlabel{my-label}{{4.10}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Prediction next sensor?}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Prediction different length of legs?}{46}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.1}Furture work}{47}}
\bibdata{bib}
\bibcite{OptoforceFig}{1}
\bibcite{OptoforceSheet}{2}
\bibcite{Guyon2006}{3}
\bibcite{MLP}{4}
\bibcite{Cortes1995}{5}
\bibcite{KnnClassification}{6}
\bibcite{Quinlan1986}{7}
\bibcite{littleDog}{8}
\bibcite{4651026}{9}
\bibcite{6784609}{10}
\bibcite{Dutta2016}{11}
\bibcite{6569179}{12}
\bibcite{Giguere06environmentidentification}{13}
\bibcite{7487541}{14}
\bibcite{7487544}{15}
\bibcite{5602459}{16}
\bibcite{5509309}{17}
\bibcite{Giguere2009}{18}
\bibcite{6386243}{19}
\bibcite{4399500}{20}
\bibcite{6027100}{21}
\bibcite{6907805}{22}
\bibcite{Optoforce}{23}
\bibcite{Optoforce2}{24}
\bibcite{7803326}{25}
\bibcite{7759112}{26}
\bibcite{7849467}{27}
\bibcite{5752869}{28}
\bibcite{4654717}{29}
\bibcite{5152327}{30}
\bibcite{6849778}{31}
\bibcite{4161556}{32}
\bibcite{4059113}{33}
\bibcite{6225128}{34}
\bibcite{5981563}{35}
\bibcite{1053964}{36}
\bibcite{Bao2004}{37}
\bibcite{5152662}{38}
\bibcite{4543710}{39}
\bibcite{5979766}{40}
\bibcite{Press:2007:NRE:1403886}{41}
\bibcite{NOFREELUNCH}{42}
\bibcite{DBLP:conf/emcr/WeissFSZ07}{43}
\bibcite{Hoffmann20141790}{44}
\bibcite{7387710}{45}
\bibcite{scikit-learn}{46}
\bibcite{runstats}{47}
\bibcite{optoRos}{48}
\bibcite{hexapod}{49}
\bibstyle{ieeetr}
