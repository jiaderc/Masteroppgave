\documentclass[USenglish]{ifimaster}  %% ... or USenglish or norsk or nynorsk
\usepackage[utf8]{inputenc}         %% ... or utf8 or applemac
\usepackage[T1]{fontenc,url}
\usepackage[section]{placeins}
\urlstyle{sf}
%\usepackage[table]{xcolor}
\usepackage[table,xcdraw]{xcolor}
\usepackage{babel,textcomp,csquotes, ifimasterforside,varioref,graphicx}
\usepackage{multirow}%kan fjernes 
\usepackage{amsmath,amssymb}
\usepackage{ tipa }
%\usepackage{xcolor} %Kan fjernes slutt
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{adjustbox}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{listings}
%\usepackage{graphicx}
%\usepackage[table,xcdraw]{xcolor}
%\usepackage[table]{xcolor}

\usepackage{tikz}
\usetikzlibrary{shadows,arrows,positioning,shapes.geometric,fit,calc}
% Define the layers to draw the diagram
\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}
\tikzstyle{container} = [draw, rectangle, dashed, inner sep=2em]
% Define block styles
\tikzstyle{materia}=[draw, fill=blue!20, text width=6.0em, text centered,
  minimum height=1.5em,drop shadow]
\tikzstyle{etape} = [materia, text width=8em, minimum width=10em,
  minimum height=3em, rounded corners, drop shadow]
\tikzstyle{texto} = [above, text width=6em, text centered]
\tikzstyle{linepart} = [draw, thick, color=black!50, -latex', dashed]
\tikzstyle{line} = [draw, thick, color=black!50, -latex']
\tikzstyle{ur}=[draw, text centered, minimum height=0.01em]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{container} = [rectangle, draw, inner sep=0.2 cm, dashed]
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
text width=5.5em, text badly centered, node distance=4cm, inner sep=0pt]
% Define distances for bordering
\newcommand{\blockdist}{1.3}\newcommand{\edgedist}{1.5}

\newcommand{\etape}[2]{node (p#1)[etape]{#2}}
\newcommand{\io}[2]{node (p#1)[io]{#2}}
\newcommand{\dec}[2]{node (p#1)[decision]{#2}}  

% Draw background
\newcommand{\background}[5]{%
\begin{pgfonlayer}{background} % Left-top corner of the background rectangle 
\path (#1.west |- #2.north)+(-0.5,0.25) node (a1) {};
% Right-bottom corner of the background rectanle
\path (#3.east |- #4.south)+(+0.5,-0.25) node (a2) {}; % Draw the background
\path[fill=yellow!20,rounded corners, draw=black!50, dashed] (a1) rectangle (a2);
\path (#3.east |- #2.north)+(0,0.25)--(#1.west |- #2.north) node[midway] (#5-n) {};
\path (#3.east |- #2.south)+(0,-0.35)--(#1.west |- #2.south) node[midway] (#5-s) {};
\path (#3.east |- #2.north)+(0.7,0)--(#3.east |- #4.south) node[midway] (#5-w) {};
\path (a1.east |- a1.south)+(8,0.1) node (u1)[texto] {\textit{#5}}; \end{pgfonlayer}}

\newcommand{\transreceptor}[3]{% 
\path [linepart] (#1.east) -- node [above] {\scriptsize #2} (#3);}


\title{Terrain classification using 3D optical force sensor}        %% ... or whatever
\subtitle{A machine learning approach}  
\author{Jiader Chou}                      %% ... or whoever 

\begin{document}
\ififorside{}
\frontmatter{}
\maketitle{}

\frontmatter{}
\chapter*{Abstract}                   %% ... or Sammendrag or Samandrag
This thesis will use optical force sensor for terrain classification. The experiment use different classifier to predict 4 different terrains...
\tableofcontents{}
\listoffigures{}
\listoftables{}

\chapter*{Preface}                    %% ... or Forord

\mainmatter{}
%\part{Introduction}                   %% ... or Innledning or Innleiing
\chapter{Introduction}                  %% ... or Bakgrunn
Humans naturally adapt their walking style on different terrain to have a stable locomotion to prevent falls. Adaption of the walking style comes of past experiences. For instance, one might experienced the difficulty of running on icy road and may cause a fall, while running on dry road will be fine. To achieve this ability, the robot must be able to distinguish different terrains.
\\
\\ 
New and improved sensors have made it possible to distinguish terrain even more accuracy. A popular sensor used is gather information visually from terrain such as camera \cite{littleDog}, laser scanners \cite{4651026}. These types of sensor gather information from terrain indirectly. While other rather to measure the properties of the terrain more directly such as tactile, joint angle, accelerometer and gyroscope. Degrave et al.\cite{6784609} investigated different types and combinations of sensors for a Quadruped Robot to identify which of them is suitable and provide most information on the terrain. The result showed that the most informative sensors were a combination of tactile sensors and proprioceptive joint angle sensors. A type of sensor which use refracted light intensity to measure the contact force has been less focused within terrain classification, that is the 3-axis optical force sensor. Due to high sensitivity, small size, light weight and low detection time \cite{Dutta2016}, the sensor suit to obtain information from terrain and distinguish them. The goal of this thesis is to use an 3D optical force sensor and investigate whether it can distinguish terrains with slightly difference such as floor and carpet.
\\
\\
To evaluate quality use of the sensor in terrain classification, this thesis will be investigating several learning algorithms and find a reliable approach. The thesis will also look into how to preprocess data, create features and select features.


\section{Outline}
The thesis is divided into five chapters: introduction, background, implementation,  experiments and results and conclusion. 

\paragraph{Chapter 1: Introduction}
The introduction chapter gives a brief introduction of the terrain classification, and the motivation in this project.

\paragraph{Chapter 2: Background}
The background chapter presents first a brief what terrain classification is about. The second section will be presenting the optical sensor used in this thesis. Following will be briefly presents background of machine learning used in this thesis. Lastly, related work of terrain classification will be presented.

\paragraph{Chapter 3: Implementation}
The implementation chapter present the experiment setup, how the data is preprocessed and used in learning process.

\paragraph{Chapter 4: Experiments and results}
The experiments and results chapter presents experiments and its results along with a short analysis.

\paragraph{Chapter 5: Discussion}
The discussion chapter will discuss results from the experiments, along with suggestions for future work. Lastly is a conclusion of this thesis. 


\chapter{Background}                  %% ... or Bakgrunn
%\section{Optical force sensor}
%Snakke litt om historien om optical force sensor
%Optical force sensors use the refracted light itensity to measure..
\section{Terrain classification}
Terrain classification is the process of identify different types of terrain by looking on its characteristics such as texture, slope, roughness, hardness and friction. For instance grass is soft and provide an amount of friction, while rocks is hard and might has less friction than grass. Outdoor terrains is more unpredictable cause of its unstructured environment and their properties change accordingly to the weather. For instance rain will soften the soil and snow will make the road slippery. Indoor in other hand, is more predictable, since it has more structured environment and the terrain will not be highly affected of any factors.


\section{Optical force sensor}
Optical force sensors use the refracted light intensity to measure the deformation of the silicon \cite{6027100}\cite{6907805}. The sensor used in this thesis is OptoForce(3D force sensor) \cite{Optoforce}. A construction of the sensor is shown on the figure \ref{fig:OptoforceBuild}. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Figures/OptoforceBuild}
	\caption{Figure showing construction of the 3d optical force used in thesis \cite{OptoforceFig}}
	\label{fig:OptoforceBuild}
\end{figure}
\FloatBarrier

The sensor consists of a light emitter (LED) and four sensing elements(photodiodes) which is wrapped within two layers, a reflective layer and a sensing surface. The four photodiodes obtain the force by measure the infrared light reflected by the reflective layer. If a force is applied on the sensing surface, the amount of reflected light to each photodiodes will change accordingly. The forces in x- and y-direction is measured from the difference in amount of reflected light between the two opposing photodiodes for each direction, while the force in z-direction is the average of the four measurements. Figure \ref{fig:OptoforceAxis} showing each direction on the sensor. Optoforce sensor is relative new sensor(2015), and the manufacturer claim the sensor can guarantee precise measurements even up to 200\% overload \cite{Optoforce2}. A several work where the sensor is used can be found in \cite{7803326,7759112,7849467}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Figures/OptoforceAxis3}
	\caption{Figure showing the x,y and z-direction for the 3d optical force used in this thesis \cite{OptoforceSheet}.}
	\label{fig:OptoforceAxis}
\end{figure}

\section {Machine learning}
Machine learning is a type of artificial intelligence where it can learn to adapt or predict from earlier dataset without being explicitly programmed. Each dataset consists of an feature vector which belong to a specified class. The training process consists of analyzing for each features vector and produce an inferred function, which is used for comparing new and unseen dataset to a class. The learning algorithm can be separated into supervised, unsupervised, reinforcement and evolutionary learning \cite{Marsland:2009:MLA:1571643}. The thesis will be focusing on supervised learning. However, the following paragraphs will briefly introduce the difference between each type.

\paragraph{Supervised learning}
Supervised learning algorithms predict new data based on labeled dataset. That is, the system in learning process know correct answers to each dataset and will base the prediction on that. The learning process usually stops when the algorithm converge towards an acceptable level of performance.

\paragraph{Unsupervised learning}
Unsupervised learning algorithms make predictions from data points without label. The system has to organize the data on its own and make prediction based on that. A common method to organize the data is by clustering.

\paragraph{Reinforcement learning}
Reinforcement learning algorithms will choose an action to each dataset and it will receive a reward indicating how good the decision was. Based on rewards, the algorithms modifies its strategy in order to get the highest reward. 

\paragraph{Evolutionary learning}
Evolutionary learning use the biological evolution such as reproduction, mutation, recombination, and selection as learning process. It is often used to find how good the current solution is.

\subsection{Classifier} \label{sub:classifier}
The classifier is where the learning process occur and produce the inferred function. Following sections will introduce technical background of five different classifiers which is intended to be used in this thesis.

\subsubsection{Neural network}
Neural network (NN) is inspired of neurons in human brain, and is one of the popular learning algorithm. It can be found in many different research field, such as signal processing, image processing, natural language processing etc. A common representation of a neuron is the perceptron shown in figure \ref{fig:NN}. It consists a set of weighted inputs $w_i$, an adder which sums weighted inputs signals and an activation function to decide whether it should fire for the current input $x_i$. By connecting many perceptrons, one will obtain neural network. Note that neurons only dependent on its inputs and error. That is, a neuron will not be affected by other neurons performance. Each neurons gives a result based on own weights and the input, adding them together, and comparing the result to its own threshold. The only thing neurons share is the input. 
\\
\\
The learning process of perceptron in supervised learning is be able to reproduce a particular pattern to a class, which consist of firing and non-firing neurons for a given input. If some of the neuron yield a wrong output, for instance a neuron did not fire when it should, then its weights will be adjusted to make it fire right next time. There is a possible to add more layers to the neural network, which make it able to handle non linearly separable problems. This is also called multi-layer perceptron (MLP), or multi neural network.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.9]{Figures/neuron.PNG}
	\caption{Figure showing a simple model of a single perceptron \cite{Marsland:2009:MLA:1571643}}
	\label{fig:NN}
\end{figure}

\paragraph{Multi-Layer Perceptron}
Multi-layer perceptron consists of two or more layers between the input and output. Those layers are also called hidden layer because its value cannot be change directly, and it is only observed in the training set. The training process can be divided into forward algorithm and backward algorithm. The forward algorithm start first by calculating the activations of the first hidden layer. Those activations and the next set of weights will be used to calculate the activations for the next layer, which could either be a hidden layer or the output. The output will then be compared to a target to compute an error. The backwards algorithm will be using the error to adjust the weights between the output-layer and hidden-layer. The algorithm stops when it has reach the inputs and changed entire weights.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{Figures/MLP.png}
	\caption{Figure showing a multi-layer perceptron with 1 hidden layer \cite{MLP}. It is possible to increase the number of hidden layers and nodes to each layer}
	\label{fig:MLP}
\end{figure}

\subsubsection{Support vector machines}
Support vector machines (SVM) algorithm was introduced by Vapnik and Chervonekis in 1963, while the standard used today is introduced by Cortes and Vapnik in 1995 \cite{Cortes1995}. In figure \ref{fig:SVM} is an instance of 2-class classification, SVM. The dotted line is the boundary for the two classes: circle and cross. To predict new set of data, it will check which side of the decision boundary it lies. If a dataset lies under the boundary line (dotted line) it will classify as cross, while circle if above. If the decision boundary was moved small amount, there is it has a high risk of misclassifying the dataset which lie close to it. This is why SVM will find the optimal separating hyperplane. It will classifies training data more correctly, and will also generalize better with new unseen data. To find the best decision boundary will be the maximizing the margin. It will be found by find the furthest hyperplane from a data point. If a dataset is non-linearly separable data, the SVM will transform the data into higher dimensional where the data is linearly separable to make the classification.


\begin{figure}[h]
	\centering
	%    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/SVM.PNG}
	\includegraphics{Figures/SVM.PNG}
	\caption{Figure showing an example of the optimal margin for a two dimensional
		two-class classification problem \cite{Cortes1995}. Each of features vector with values according to the x- and y-axis, represents as classes: circles and crosses. The dotted line is the decision boundary and tell where each class belongs to. The classes that are hatched indicate they lies on the straight line. }
	\label{fig:SVM}
\end{figure}



\subsubsection{Naive bayes}
Naive Bayes algorithm is based on Bayes’ theorem with the assumption of independence between every pair of features, hence the name “naive”. Bayes's theorem in machine learning is often used to find the probability that a data set A occur, based on the data set B. The bayes theorem can be formulated as \cite{Press:2007:NRE:1403886}:
\begin{equation}
P(A \vert B) = P(A)\frac{P(B \vert A)}{P(B)}
\label{eq:bayesNaivews2}
\end{equation}
The $P(A \vert B)$ is the probability of A given that B has occurred, while $P(A \vert B)$ is the probability of B given that A has occured. $P(A)$ and $P(B)$ are unconditional probabilities. The bayes theorem suit to mathematical express the terrain identification problem, and allow to evaluate unexpected mismatch between sample classes and the real environments. In equation \ref{eq:bayesNaivews2}, the A could represent possible terrains that is expected to predict, while B is the data from sensor. According to the equation \ref{eq:bayesNaivews2} the $P(A \vert B)$ will be the likelihood that the terrain is this with these data from senor. The prediction is by use the highest probability among the possible terrains. 

\begin{comment}


Several research based the terrain classification on naive bayes which has given good result \cite{6225128, 5981563}. The bayes' theorem suit to mathematical express the terrain identification problem \cite{Giguere06environmentidentification,6225128}. This is mathematically simple and allow to evaluate unexpected mismatch between sample classes and the real environments. The terrain classification problem can be expressed as \cite{6225128}:

\begin{equation}
P(\theta_{l}\vert X)={p(X\vert \theta_{l})P(\theta_{l})\over p(X)}
\label{eq:bayesNaivews}
\end{equation}

The $\theta_{l}$ represent the class, which would be the possible terrains the robot is expected to predict. The X represent the observations, which are information from different sensors, also called feature vector. On the formula the \ref{eq:bayesNaivews} $P(\theta_{l}\vert X)$ is the conditional probability distribution. $P(X\vert \theta_{l})$ is the likelihood that the terrain is has with these observations, and the $P(\theta_{l})$ is the priori distribution of the classes, and $p(x)$ is the
distribution of the observation. Classification is done by selecting a class that maximizes the a posteriori probability $P(\theta_{l}\vert X)$ according to the Maximization of A Posteriori (MAP) decision rule

\begin{equation}
p(X\vert \theta_{l})P(\theta_{l})=\displaystyle\mathop{\max}_{j}\{p(X\vert \theta_{j})P(\theta_{j})\}
\label{eq:decision}
\end{equation}

The CPDF for each class can be estimated either parametrically or non-parametrically. An accurate nonparametric density is hard to estimate, especially when the number of features is high. One of the most popular parametric probability density functions is the normal distribution, which only requires an estimate of the mean $M_l$ and covariance matrix $\sum_1$ for the class $\theta_l$

\begin{equation}
p(X\vert \theta_{l}) = {1\over (2\pi)^{N/2}\vert \Sigma_{l}\vert ^{1/2}} \times{exp}\{-{1\over 2}(X-M_{l})^{T}\Sigma_{l}^{-1}(X-M_{l})\} 
\label{eq:bayesLast}
\end{equation}
\end{comment}

\subsubsection{K-nearest neighbors }
K-nearest neighbors (KNN) is one of the simple classifiers presented by Cover and Hart \cite{1053964}. The classification process of new data consists of looking the k-nearest data points and classify the class which consist most classes. An example is shown \ref{fig:KNN}. All the blue squares and red triangles are the training data, while the green circle is to be classified. The straight and dashed circle illustrate which data set is taken account when k is set either 3 or 5. If k set to  3, the circle will be classified as triangle, since the tree nearest neighbor consist more triangles than squares. If k set to 5, then the circle will be classified as square.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{Figures/KNN.png}
	\caption{Figure showing an example of a KNN classification \cite{KnnClassification}. The green circle is to be classified to either blue square or red triangle. The straight circle is when k = 3, while the dashed circle is when k = 5.}
	\label{fig:KNN}
\end{figure}

The most common method to find the k-nearest datapoint is to calculate the Euclidean Distance. The euclidean distance can be expressed as \cite{Bao2004}:


\begin{equation}
D(x,y)=\sqrt{\sum_{i=1}^{m}(x_{i}-y_{i})^2}
\label{eq:edistance}
\end{equation}
The x and y from equation \ref{eq:edistance} represent the actual and unseen class, and m is the number of features to each of classes in x and y. The algorithm will then count k classes with shortest distance to determine which class the unseen data belongs to. A weakness of using Euclidean distance function is that if one of the vector has a large range, then it will dominate other attributes. In order to avoid this issue, it is common to scale the feature, described in section \ref{subsec:scaling}


\subsubsection{Decision tree}
The decision tree is a non-parametric classifier presented by JR Quinlan \cite{Quinlan1986}. The process of the decision tree is constructing a tree consisting of nodes and edges using the dataset. Each of nodes represents a test on one features, and the edges represent an outcome of the test. Leaf nodes represent the outcome class. Predicting process is following a path from the root to a leaf node.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{Figures/decisionTree.PNG}
	\caption{Figure showing an example of a simple decision tree \cite{Quinlan1986}. This decision tree classify a day to be P or N based on outlook, humidity and windy.}
	\label{fig:SVM}
\end{figure}


\section{Features} \label{features}
An important part of achieving a good classification, is finding good features from sensor data. The features is what distinguish between classes and will be used as learning set. Thus, finding good features is crucial to achieve a accurate classifier.

\subsection{Curse of dimensionality}\label{curseDim}
The curse of dimensionality occurs when one include too many features to the input vector. When the dimensionality of features vector increase, the complexity of underlying pattern might increase and the performance of the classifier will be degrade. To prevent the curse of dimensionality one can add more samples to uncover the underlying pattern.

\subsection{Features extraction} \label{feature_extraction}
Feature extraction is the process to build a new set of features from the original set and use it as training set. Those extracted features should make it easy for a classifier to distinguish between the various classes. A common method is extracting statistical features.

\subsubsection{Statistical features} \label{sub:statical}
The following paragraphs will be explaining five different statical features, which will be used in this thesis.

\paragraph{Mean}
The mean is generally referred to the average, and is defined as sum of the values divided by the number of values\cite{Press:2007:NRE:1403886}:

\begin{equation}
\bar{x} = \frac{1}{N}\sum_{N-1}^{j=0}x_{j}
\label{eq:mean}
\end{equation}


\paragraph{Variance}
Variance describe the spread between numbers in a data set. The variance can be written as\cite{Press:2007:NRE:1403886}:

\begin{equation}
Var(x_0\dotsc X_{N-1})  = \frac{1}{N}\sum_{N-1}^{j=0}(x_{j}-\bar{x})^2
\label{eq:variance}
\end{equation}

\paragraph{Standard deviation}
Standard deviation is a measure of spread of a data set from its mean. High deviation indicate that the data points are further from the mean. This can be calculated by taking the square root from variance\cite{Press:2007:NRE:1403886}:

\begin{equation}
\sigma(x_0\dotsc X_{N-1})  = \sqrt{Var(x_0\dotsc X_{N-1})}
\label{eq:std}
\end{equation}

\paragraph{Skewness} 
Skewness describes asymmetry of a distribution. The formula is\cite{Press:2007:NRE:1403886}:
\begin{equation}
Skew(x_0\dotsc X_{N-1})  =  \frac{1}{N}\sum_{N-1}^{j=0}\left [ \frac{x_j-\bar{x}}{\sigma} \right ]^3
\label{eq:skew}
\end{equation}

The skewness can be either negative or positive depending on whether data points are skewed to the left or to the right. If data is skewed to the left indicate a negative skewness, while positive skewness is when the data is skewed to the right. An illustration of both positive and negative skewness is shown in figure \ref{fig:skew}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Figures/Skewness}
	\caption{Skewness}
	\label{fig:skew}
\end{figure}

\FloatBarrier

\paragraph{Kurtosis}
Kurtosis measure the peak and tails of a distribution relative to a normal distribution. Using kurtosis might help to understand general characteristics about the distribution of the data. The formula is\cite{Press:2007:NRE:1403886}:
\begin{equation}
Kurt(x_0\dotsc X_{N-1}) = \left \{ \frac{1}{N}\sum_{N-1}^{j=0}\left [ \frac{x_j-\bar{x}}{\sigma} \right ]^4 \right \}-3
\label{eq:kurtosis}
\end{equation}

A positive kurtosis of a distribution has a sharper peak and heavier tails relative to normal distribution. While a negative kurtosis has flatter peak and lighter tails relative to normal distribution. An illustration of both positive and negative kurtosis is shown in figure \ref{fig:kurtosis}


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Figures/Kurtosis}
	\caption{Kurtosis}
	\label{fig:kurtosis}
\end{figure}

%http://greenteapress.com/thinkstats/thinkstats.pdf

%\paragraph{Time domain}
%\paragraph{Fourier transform}


\subsection{Features selection}\label{selection}
The process in feature selection is to select a subset of features from the original set. Selecting good features has benefit of increasing classifier performance, prevent the curse of dimensionality mentioned in section \ref{curseDim} and reducing storage requirements and training time. Note that a features can individually be completely useless, but relevant when used together with other features \cite{Guyon2006}. 
There are three types of feature selection algorithms: filter-, wrapper- and embedded methods as shown in figure \ref{fig:selection}. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{Figures/FilterWrapperEmbedded.PNG}
	\caption{The figure showing the three approaches of feature selection \cite{Guyon2006}. (a) filter method (b) wrapper method and (c) embedded method.  The shades show the components used by the three methods.}
	\label{fig:selection}
\end{figure}


\paragraph{Filter}
Filter feature selection is independent of any classifier. It uses statistical measures to assign each feature a score. Features will either be kept or removed based on the score. The filter methods are considered fast and effective, specially when the number of features is large and the number of available training examples comparatively small.  


\paragraph{Wrapper}
Wrapper feature selection will try different combination of the feature set, evaluate by a classifier and keep the feature set with best result.


\paragraph{Embedded}
Embedded feature selection perform feature selection as part of the learning procedure and are usually specific to given classifier.

\subsection{Features scaling}
\label{subsec:scaling}
To reduce bias effect cause by skewed distributions, it is common to standardization the feature vectors. By scaling each features, it that avoid features with big number dominate compared features with small numeric ranges. It particularly affect classifier which use distance between classifier such as KNN and SVM.  By standardized feature values the features will weights equally in their representation.


\section{Model validation}
Model validation relate to evaluate the performance of a classifier. 

\subsection{No free lunch theorem} \label{seq:nofree}
The well-known no free lunch theorem\cite{NOFREELUNCH} in machine learning states that there is no best classifier for every problem. That is, even if a model achieve great performance for one problem, might not hold for another problem. Thus, it is recommended to apply several classifier.

\subsection{Ovefitting and underfitting}
Overfitting and underfitting the data is a issue in machine learning which cause a poor performance of classification. Overfitting occurs if there are too many training data or if it has adapted to the noise within data set. While underfitting occurs if there are not enough training data and will not be able to generalize new data set. An example for each case is shown in figure \ref{fig:fitting}. The cross-validation estimate how accurately the classifier model will perform in practice, which might prevent overfitting or underfitting the data.
\begin{comment}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{Figures/All.png}
	\caption{The figure showing an example when the classifier is underfitted, overfitted or optimal.}
	\label{fig:fitting}
\end{figure}
\end{comment}
\begin{figure}[h]
	\begin{subfigure}{0.5\linewidth}
		\centering
		\includegraphics[scale=0.43]{Figures/Overfitting}
		\caption{Overfitting}
		\label{fig:over}
	\end{subfigure}%
	\begin{subfigure}{.5\linewidth}
		\centering
		\includegraphics[scale=0.43]{Figures/Underfitting}
		\caption{Underfitting}
		\label{fig:under}
	\end{subfigure}\\[1ex]
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[scale=0.43]{Figures/Finefitting}
		\caption{Optimal}
		\label{fig:optimal}
	\end{subfigure}
	\caption{Figur illustrate when a model is \ref{fig:over} overfitted, \ref{fig:under} underfitted and \ref{fig:optimal}optimal }
	\label{fig:fitting}	
\end{figure}

\FloatBarrier

\subsection{Cross-Validation}
Cross-validation is used to assess the quality of a model. The process of cross-validation is to first remove some of the data before the training begins. After the training, it will use the removed data to test the performance. The intention is to evaluate the classifier performance in more realistic scenario by predicting new and unseen data. The K-fold is a common cross-validation method.

\paragraph{K-fold}
The process of k-fold is to partitioned the data into k subset, where one subset is used for testing and the other are used for training. When the trained model has assessed the test set, a new subset is selected as test set. This process is repeated k times, that is when all subsets have been used as a test set. Setting k to the length of feature vectors is also know as leave-one-out cross-validation (LOOCV). LOOCV only use one feature vector as test set, while the rest as training set shown in figure \ref{fig:kfold}. The advantages is that using as many training samples as possible.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{Figures/Kfold}
	\caption{The figure showing an instance of k-fold cross validation. In this case the k is set to be 8 which is also the length of feature vectors}
	\label{fig:kfold}
\end{figure}

%Se: Rigidity-based surface recognition for a domestic legged robot.


\subsection{Evaluating Classifiers}\label{subsec:evalclf}
Evaluation of the performance to classifier can be done by calculate metrics based on correct or wrong output. For instance a two-class classifier with classes, "postive" and "negative" will have four different outcomes:

\begin{enumerate}
	\item True postive (TP) is correct prediction of class positive
	\item True negative (TN) is correct prediction of class negative
	\item False positive (FP) is wrong prediction of class positive
	\item False negative (FN) is wrong prediction of class positive
\end{enumerate}

Those four variables can be further used to calculate the precision, accuracy, recall and f-score.

\paragraph{Precision}
Precision gives the number of correct detected class members.
\begin{equation}
Precision = \frac{TP}{TP + FP}
\label{eq:prec}
\end{equation}

\paragraph{Accuracy}
Accuracy gives the ratio of correct prediction. 
\begin{equation}
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\label{eq:acc}
\end{equation}

\paragraph{Recall}
Reacall gives the number of detected actual class members.

\begin{equation}
Recall = \frac{TP}{TP + FN}
\label{eq:recall}
\end{equation}

\paragraph{F-score}
F-score is a balanced measure of recall and precision 
\begin{equation}
\textit{F-score} = 2*\frac{Precision*Recall}{Precision + Recall}
\label{eq:fscore}
\end{equation}
%\part{The project}                    %% ... or ??
\FloatBarrier
The accuracy will tell the overall performance of the model. However, there is a possibility that the model only classify three of four terrains correctly and still get a high accuracy. Thus, it will be recommended to look at the f-score. A low f-score indicate that the class either has a low precision, recall or both. Low precision indicate that the classifier has difficulty to predict the currently terrain, while low recall indicate that is more likely that a terrain is to be classified in other terrains.
\\
\\
It will be interesting to see which of class was easier to predict than others. This can be seen by using confusion matrix. The confusion matrix consists a square matrix with one row for predicted class, and and column for actual class (or vice-versa).
An example of confusion matrix is shown on table \ref{tab:cmatrix}

\begin{table}[h]
	\centering
	\begin{tabular}{ll|l|l|l|}
		\cline{3-5}
		&  & \multicolumn{3}{c|}{Actual} \\ \cline{3-5} 
		&  & $C_1$ & $C_2$ & $C_3$ \\ \hline
		\multicolumn{1}{|l|}{\multirow{3}{*}{Predicted}} & $C_1$ & 8 & 0 & 0 \\ \cline{2-5} 
		\multicolumn{1}{|l|}{} & $C_2$ & 5 & 8 & 1 \\ \cline{2-5} 
		\multicolumn{1}{|l|}{} & $C_3$ & 5 & 3 & 8 \\ \hline
	\end{tabular}
	\caption{A confusion matrix of 3-class classification.}
	\label{tab:cmatrix}
\end{table}


\section{Related work}
The terrain classification has been applied both wheeled and legged robots. Wheeled robots have the benefit of achieving stable locomotion by changing their speed on different terrains, while the legged robots must either change their gait, walking speed or both. Changing the gait for a legged robot can be complex, but has the benefit of traverse on more difficult terrains. In this thesis a legged robot will be used to perform terrain classification.

\subsection{Types of legged robots}
Many types of legged robot has been addressed in terrain classification. Mostly reviewed study has been using quadruped \cite{6784609,littleDog,6849778,Hoffmann20141790} and hexapod \cite{Walas2015,26b23e912c654fe4b7478fd910130195,6569179} cause of its stability. However a few has used one legged robot \cite{5602459}. The following paragraphs will introduce several platform of different legged robots.

%http://e-collection.library.ethz.ch/eserv/eth:7893/eth-7893-02.pdf#search=%22terrain classification%22
%file:///C:/Users/Jay/Downloads/Paper_MME_2006_JATMachado_MFSilva%20(2).pdf
%http://www.robotplatform.com/knowledge/Classification_of_Robots/legged_robots.html
%http://www2.cs.siu.edu/~hexmoor/classes/CS404-S09/RobotLocomotion.pdf
%http://www.idt.mdh.se/kurser/ct3340/ht12/MINICONFERENCE/FinalPapers/ircse12_submission_21.pdf

\paragraph{Monopod}
The monopod is a simple legged robot design, with one leg. The locomotion of monopod robots is performed through hops and it is also called as hopping robots. Having only a single point of ground contact, the challenging is achieving the stability. An example of one legged robot is developed by Marc Raibert shown in figure \ref{fig:onlegg}.


\paragraph{Biped}
Biped is robot with two legs. The studies on biped robots have been popular research field, especially towards developing humanoids. Creating a humanoid implicate that the robot is able to imitate humans behavior, such as the walking, running, jump, traverse on stairs. A successive humanoid is the NAO robot \cite{NAO}, shown in figure \ref{fig:nao}. Not only is NAO robot able to walk, but it is also capable to see, hear, speak and feel. However, using a biped for terrain classification is still unsuitable since it is hard to maintain stability on rough terrain.

\paragraph{Quadruped}
Quadruped is robot with four legs to walk and is inspired from animals. The BigDog \cite{Raibert200810822} shown in figure \ref{fig:bigDog} has shown impressive performance. With hydraulic actuators make the BigDog stronger and is able to carry load from 50kg to 150kg depend on the terrain. Other abilities are being able to jump, run and maintain the stability even it get pushed or walking on slippery terrain. A reason of mostly work using quadruped is its stability. By having more legs make the more stable and is capable to traverse through terrain without falling. However it is more complex to control their legs.

\paragraph{Hexapod}
Hexapod is six legged robot and is inspired of insect, mostly towards spiders. By having more legs provides a more stable walking system. However, the leg coordination might be more complex, due to controlling six legs. An example of hexapod developed from The FZI Research Center for Information Technology is the LAURON robot. Many versions of Lauron has been developed, and currently used is the Lauron V shown in figure \ref{fig:LAURON}. Because of its stability like the quadruped, hexapod is also popular used robot within terrain classification studies.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.22\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Hopper}
		\caption{One legged robot \cite{Raibert:1986:LR:5948.5950}}
		\label{fig:onlegg}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{0.22\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Nao_Robot}
		\caption{The NAO robot \cite{NAOImage}}
		\label{fig:nao}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{0.22\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/BigDog}
		\caption{The bigdog \cite{Raibert200810822}.}
		\label{fig:bigDog}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{0.22\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Lauron}
		\caption{Lauron V robot \cite{6878051}.}
		\label{fig:LAURON}
	\end{subfigure}
	\caption{Pictures of animals}\label{fig:robots}
\end{figure}

\FloatBarrier

\subsection{Importance of terrain classification}
The importance of terrain classification for legged robots is that the terrain has a major factor affecting the decision for the gait change \cite{6569179}. Most of the legged robot has the benefit of changing their gait and walking speed to achieve a stable locomotion. For instance a running gait can be efficient on flat road, but fail to maintain the stability when used on ice, cause of slipping. An example of application is shown in Giguere et al. \cite{Giguere06environmentidentification}, where a amphibious legged robot can switch from walking to swimming gait, according to which of the terrain it is on. 
\\
\\
It has been shown that different controllers were suited for different terrain by letting quadrupedal robot hopping on soft and hard terrain \cite{7487541}. Other has investigated the effect of performance with different gaits parameters on different terrains \cite{6569179}. Some of the result showed that the energy consumption and the walking speed is tied to the terrain type. That is, a trade-off between the physical speed and the power consumption of the robot can be achieved by controlling the cycle-frequency of the leg rotation.


\subsection{Terrain sensing}
In order to classify various of terrains, the system must obtain information from the terrain either by remote sensing, local sensing or both.

\paragraph{Remote sensing}
The remote sensing obtain information of a terrain from a distance and do not measure the terrain physically. The camera is most widely used and discriminating the terrain is based on analyzing images.
\\
\\ 
Filitchkin et al. \cite{littleDog} presents an visual terrain classification by using a single, compact camera to change the gait patterns of a quadruped robot. Three types of gaits were used during the experiment, a gait designed for flat surface, a gait for rough terrain and a mixture of the two first. To know which gait should be chosen for each terrain, an initial test by assigning a gait to each terrain type is required. There were totally four different terrain: small rocks, rocks, grass and tile. Lastly, the experiment was let the robot execute a terrain classification cycle every few steps and switched to one of three gait according which terrain it is on. Robot performance was measured by comparing the traversal time between for each three gait and the changing gait. The result shown that the changing gait is able to terrain classification and traverse through the terrain faster. The other two gait were fast, but was not able to classify big rocks, while the last gait was able to classify all terrain but had slower traverse time.
\\
\\
Plagemann et al. \cite{4651026} used laser ranger finder to predict terrain elevation at unseen locations.
The researches extended the Gaussian process model to achieve a more accurate prediction of elevations. The result show that the proposed method is capable of accurately predicting elevations in the presence of noise even at unobserved locations. These features allowed them to plan foot trajectories of the robot to reach the goal location. 
\\
\\
A weakness of using the remote sensors, is that it does not give insight into the characteristic of currently terrain. For instance remote sensor might has difficulties to distinguish between a terrain that is covered with either compacted or uncompacted snow. An another option to measure terrain directly is by local sensing. 

\paragraph{Local sensing}
Local sensing measure aspects of the interaction between the robot and terrain as the robot walk through. This gives a measurement of mechanical terrain properties and provide useful information such as how the environment is affecting currently robot performance. 
\\
\\ 
Stejskal et al. \cite{7487544} present a road following hexapod robot by using the feedback from robot servo drives. The road following consists of let the robot blindly walk on road. After each gait cycle, the robot will determines whether it is on new terrain or on road. If it is determined as off road, then the robot will steer back to the road. Data from the servo provides information about the leg motion which were position error, current speed and torque. Three different terrains, asphalt, dirt and grass were used during the experiment. The robot was most confused by dirt, which had about 86\% of misclassified samples. The author states that the transition from asphalt to dirt was usually flat, which means that the leg motion of walking on flat dirt has a similar leg motion as walking on asphalt. Beside of that, the overall result of terrain classification had an accuracy of 96.2\%, which can be considered as feasible approach and data from leg motion keeps the robot on the road.
\\
\\
Kim et al. \cite{5602459} used the ground reaction force and torque sensors of an one-legged robot due to terrain classification. The goal of the research was to compare the performance between neural network and support vector machine. Four different terrains were used in the experiments which were flat, grass, sand, and gravel. The data were collected by walking through each terrain many times. Different features were extracted from the data, and partitioned into a training and test set. The result shown the support vector machine got an accuracy on 78.75\%, which performed slightly better than neural network on 78.6\%.
\\
\\
Hoepflinger et al. \cite{5509309} present a novel approach to terrain classification for legged robots by using properties from joint motor currents and force sensing resistor. The goal was to improve the guiding of foot placement and stability of legged robots in rough terrain. Usually experiments is done by having a robot walk through terrains. However in this experiment the author separated one of the legs robot and mounted to a sample holder of a testbed. The first experiment consist of distinguish four different shaped terrain: a convex and a concave cone, a convex hemispherical bulge, and a concave hemispherical indentation. The data were collected by the knee-joint oscillated slightly with an amplitude of approximately one degree on the terrain. In the second experiment was to distinguish between three different types surfaces such as abrasive paper and a low friction PTFE coating. Collecting of data were done by performing a scratching motion on the terrain. The result of terrain shape classification had a high success rate. Convex cone and concave cone had 100\% accuracy, while the concave hemisphere bulge 95\% and 80\% on for the convex hemispherical bulge. Regarding surface classification show that the algorithm performed slightly worse. A type of an abrasive paper had a accuracy of 53.3\%. Even a low accuracy the author state it is overall an satisfy result, since the average correct prediction of different types of abrasive paper was two of three, and prediction of teflon coated surface had an high accuracy 93.3\%.
\\
\\
Terrain classification with other type of local sensor research of can be found in \cite{Giguere2009,6386243,6569179,6569179,4399500}

\subsection{Learning algorithms}
There is a vast number of classifiers and various has been used within the terrain classification such as neural network \cite{6784609,5752869,4654717}, adaptive bayesian filtering \cite{5152327,6849778}, support vector machines \cite{5602459,4161556,4059113} and decision tree \cite{6849778}.
\\
\\
The no free lunch theorem described in section \ref{seq:nofree} can be seen in previous work has shown that SVM, KNN and naive bayes gave higher accuracy than the decision tree \cite{DBLP:conf/emcr/WeissFSZ07}, while in \cite{6849778} achieved a better performance on SVM, decision tree and naive bayes than KNN. It is therefore common to build several algorithms, and chose the best of them for the specified problem. 
\\
\\
Mostly study based their terrain classification on supervised learning. However, Giguere and Dudek \cite{Giguere2009} presented a new clustering method to terrain classification using unsupervised learning. This make a robot to be able automatically distinguish terrain without any human interaction or feedback. Another work of the same authors
\cite{5752869} made a tactile probe and demonstrated that it can be used in unsupervised learning.
 
\subsection{Features} \label{sub:relatedfeatures}
As mentioned in section \ref{features} finding good features is a crucial part of classification process. Earlier work has extracted features in combination of statistical features in the time domain with frequency domain features \cite{5152662} \cite{Giguere2009} \cite{5509309}. While others only use the frequency domain \cite{4543710} \cite{5979766}.
\\
\\
Giguere and Dudek \cite{5152662} extracted features such as mean, variance, skewness, kurtosis, fifth moment and sum of the variation over time in time domain. While in frequency domain where the sum of higher half of amplitude spectrum extracted.
\\
\\
Hoffmann el at. \cite{Hoffmann20141790} defined features in time domain such as, minimum, maximum, mean, kurtosis, skewness, median, standard deviation, approximation of the integral, amplitude of Hilbert transform. Other features was extracted in frequency domain such as frequency with highest amplitude and its magnitude, and similar to the second and third highest amplitude. 
\\
\\
Kertész \cite{7387710} computed median, maximum, skewness and root mean square from of the accelerometer angles in x, y and z-direction. Those features were also extracted in frequency domain for the z-direction. Features extracted from force sensors were interquartile range, maximum, skewness, RMS amplitude and the highest amplitude in frequency domain.
\\
\\
Best el at.\cite{26b23e912c654fe4b7478fd910130195} extracted five statistical features in domain such as minimum, maximum, mean median and standard deviation. However some of statistical features is also calculated in frequency domain with the energy additionally.
\\
\\
As it can be seen that many of the features is extracted by statistical features which is described in section \ref{sub:statical}. An example of extracting good features can be seen in \cite{5602459}. Using statistic with support vector machine gave an accuracy on 40\%, while principal component analysis gave an accuracy on 78.75\%. Note that the author only used variance, kurtosis and skewness as statistic features. 

\subsection{Validation}\label{subseq:validation}
A common method of validation is using the k-fold cross-validation \cite{DBLP:conf/itat/MrvaF15,6784609,6386243,Hoffmann20141790,6849778,7387710}. However the choice of selecting k vary. A common k value is to be set either two \cite{DBLP:conf/itat/MrvaF15,6784609}, 10 \cite{26b23e912c654fe4b7478fd910130195,6386243,Hoffmann20141790,6849778,7387710} or equal the length of feature vectors \cite{26b23e912c654fe4b7478fd910130195}.
\\
\\
Mrva et al. \cite{DBLP:conf/itat/MrvaF15} used 2-fold cross validation and achieved a overall accuracy 99.4\%, and states the possibility of obtaining 100\% with more folds. Best el at. \cite{26b23e912c654fe4b7478fd910130195} used 10-fold cross validation and achieved a high precision and recall for all five terrains, while leave-one-out-cross validation let the classifier being confused between grass and concrete terrains. 
\\
\\
As stated in \cite{7387710}, the k-fold gives a reasonable estimate of the performance, however, it does not tell how well it predict on unseen data. This is because the experiment always use same samples where it involve in either training or testing. The model might be less generalized, data are more likely referring to themselves and will have difficulty of predicting unseen data. Mostly authors is aware of the this and has rectified it by partitioned the samples to make the training and test set independent \cite{26b23e912c654fe4b7478fd910130195}. The learning process will only be used from a certain set, and test is from other set.
\\
\\
Not all studies evaluated their models by k-fold cross-validation, but either with new data to get a better estimation or real accuracy \cite{5509309,Walas2015,5752869}. A more simple method of validation is to partitioned randomly the data set with 70\% used for training, and the rest used for testing \cite{5752869}. The most realistic scenario is to base the evaluation by having a robot traversing through different terrains \cite{DBLP:conf/itat/MrvaF15}.



\chapter{Implementation}\label{ch:implementation}        %% ... or ??
This chapter intends to explain the various choices which has been made to create machine learning models.


\section{Tools and environment}

\subsection{Implementation language}
There are many choices of programming language, however the robot use a software framework developed for robot applications, Robot Operating System (ROS). The benefit of ROS is that processes can be grouped into packages, which can be easily shared and distributed. This allow parallel execution of the data collection and class prediction in real time. Thus, it is recommended to use programming language which are supported for ROS such as C++ and Python. 
\\
\\
Reading data from optical force sensor is using the package from \cite{optoRos}. The implementation publish data from the sensor, which make it possible for other module to fetch the data by subscribing to the node. Segmentation, which will be described later in section \ref{subseq:segmentation} is implemented in C++. The reason of implementing data segmentation in C++ is because it is faster than Python which can deal to store and delete data stream better. However, C++ does not provide many learning libraries, so the learning approach is implemented in Python. Python provide lots of libraries which reduce developing time. The libraries are well-documented and have the freedom to customize each algorithm to use. In this project libraries such as scikit-learn, scipy and runstats will be used to test each of different classifiers described in section \ref{sub:classifier}.

\paragraph{Scikit-learn}
Scikit-learn \cite{scikit-learn} is an open source library that provide tools for data mining and data analysis. The library is dependent on numpy, scipy and matplotlib. All of classifiers, and preprocessing data tool are from this library. 

\paragraph{Runstats}
Runstats \cite{runstats} is used to compute statistics, such as max, mean, skew, variance and standard deviation where some of them is described in section \ref{sub:statical}.

%\part{Conclusion}                     %% ... or Konklusjon

\subsection{Robot}
The robot used in this thesis is an Quadruped Robot developed at the University of Oslo, which is shown in figure \ref{fig:robot}. The legs are about 45 cm long and mounted with optical force sensors. Four different gait is made by evolutionary algorithm and is developed by Nygaard et al. \cite{7850167}. Two gaits is single-objective (SO), while the other multi-objective optimization (MO). Only one gait is used in this project. The reason is that the other gait had issues while walking on the soft mat. The robot either got stuck with slow gait or fallen down with fast gait. The gait used is a balanced gait which let the robot go straight forward. 


\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/Robot3}
    \caption{Figure showing the Quadruped Robot developed at the University of Oslo, which was used in all experiments}
    \label{fig:robot}
\end{figure}
\FloatBarrier

\subsection{Terrain} \label{seq:terrain}
Four different terrains is used in all experiment: floor, carpet, soft mat, and hard mat shown in figure \ref{fig:terrains}. A reason of choosing those is to get a more challenging task for classifier to distinguish them, because of similar properties between them. The intuition is that if the algorithm manage to discriminate between floor and carpet might indicate that it is able to distinguish mostly of the terrains. Floor, carpet and hard mat  has the most similar properties and is also the most difficult to distinguish. They are all slippery and has nearly equally hardness. Soft mat differ from the other with its softness and high friction. The experiments will be investigating whether the classifier can distinguish terrain with minor differences.

\begin{comment}
\begin{figure} 
\centering
   \begin{subfigure}[b]{0.55\textwidth}
   \includegraphics[width=1.5\linewidth]{Figures/Gulv2}
   \caption{Terrain 1: floor}
   \label{fig:Ng1} 
\end{subfigure}

\begin{subfigure}[b]{0.55\textwidth}
   \includegraphics[width=1.5\linewidth]{Figures/Teppe2}
   \caption{Terrain 2: carpet}
   \label{fig:Ng2}
\end{subfigure}
\end{figure}

\begin{figure} \ContinuedFloat
\begin{subfigure}[b]{0.55\textwidth}
   \includegraphics[width=1.5\linewidth]{Figures/Hardmatte2}
   \caption{Terrain 3: hard mat}
   \label{fig:Ng2}
\end{subfigure}

\begin{subfigure}[b]{0.55\textwidth}
   \includegraphics[width=1.5\linewidth]{Figures/MykMatte2}
   \caption{Terrain 4: soft mat}
   \label{fig:Ng2}
\end{subfigure}
 \caption{The figure showing 4 different terrains used in this project} 
\label{fig:terrains}
\end{figure}
\end{comment}


\begin{figure*}[h]
        \centering
        \begin{subfigure}[b]{0.475\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Figures/Gulv2}
            \caption[Floor]%
            {{\small Floor}}    
            \label{fig:mean and std of net14}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.475\textwidth}  
            \centering 
            \includegraphics[width=\textwidth]{Figures/Teppe2}
            \caption[]%
            {{\small Carpet}}    
            \label{fig:mean and std of net24}
        \end{subfigure}
        \vskip\baselineskip
        \begin{subfigure}[b]{0.475\textwidth}   
            \centering 
            \includegraphics[width=\textwidth]{Figures/MykMatte2}
            \caption[]%
            {{\small Soft mat}}    
            \label{fig:mean and std of net34}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.475\textwidth}   
            \centering 
            \includegraphics[width=\textwidth]{Figures/Hardmatte2}
            \caption[]%
            {{\small Hard mat}}    
            \label{fig:mean and std of net44}
        \end{subfigure}
        \caption[ ]
        {\small Four different terrain used for classification} 
        \label{fig:terrains}
    \end{figure*}

\section{Data from optical force sensor}
This section will first describe how the measurement from sensor gathered. Next, it will present how the data is segmented into sequences and used as the basis for creating feature vectors.

\subsection{Data collection}
Reading from the sensor is set to default 100Hz. A stable gait is used to walk 10 step on each terrains. The runs were recorded into rosbag, which make it possible re-simulate the run. Five runs for each terrain, and in total 20 runs were recorded. Data stream from one sensor for each run in each terrain is shown in figure \ref{fig:gtmgraf}.

\begin{comment}


\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/gulvgraf}
	\caption{Figure showing \texttt{rqt\_plot} of a testrun on the floor.}
	\label{fig:graphf}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/teppegraf}
	\caption{Figure showing \texttt{rqt\_plot} of a testrun on the carpet terrain.}
	\label{fig:grapht}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/mattebgraf}
	\caption{Figure showing \texttt{rqt\_plot} of a testrun on the hard mat terrain.}
	\label{fig:graphhm}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/mykmattegraf}
	\caption{Figure showing \texttt{rqt\_plot} of a testrun on the soft mat.}
	\label{fig:graphmm}
\end{figure}
\end{comment}

\begin{figure} [h]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/gulvgraf}
		\caption{Floor}
		\label{fig:gulvgraf} 
	\end{subfigure}
	
	\begin{subfigure}[b]{\textwidth}
			\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/teppegraf}
		\caption{Carpet}
		\label{fig:teppegraf}
	\end{subfigure}

	\begin{subfigure}[h]{\textwidth}
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/mattebgraf}
	\caption{Hard mat}
	\label{fig:mattebgraf}
	\end{subfigure}

\end{figure}
\begin{figure}[h] \ContinuedFloat
	\begin{subfigure}[b]{\textwidth}
			\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/mykmattegraf}
		\caption{Soft mat}
		\label{fig:mykmattegraf}
	\end{subfigure}
	\caption[]{Figure showing data stream for each terrain. (a) floor (b) carpet (c) hard mat (d) soft mat }
	\label{fig:gtmgraf}
\end{figure}


\FloatBarrier


\subsection{Analyzing data from sensor}
Analyzing the data is to find common characteristics and be able to segment desired data. Sensor data arrives in a stream as shown in figure \ref{fig:gtmgraf}. The periodic sequences is for each step. A common characteristic for all terrain is when the foot is in the air, then x,y, z-direction will have minor change and is almost constant. This characteristic will be used to segment desired data described in next section \ref{subseq:segmentation}. 

\subsection{Data segmentation} \label{subseq:segmentation}
An appropriate method to segment data is by sliding window algorithm. However, there are factors taken in account, which made it not to use the algorithm. It is difficult to decide an acceptable size of the window, difficulty of determining whether the data is relevant from the window and too big window size is not efficient. Thus, an algorithm to segment data was created. 
\\
\\
In the thesis it is considered that the most informative data of terrain is from when the foot is on ground to it is in the air. In order to collect the interested data is firstly to detect when a foot is in air. That is when there are minor change in x,y,z-direction. When there are big change in each direction, start to store the data from sensor into an array, and stop when it is in the air again. Each step will be used as a sample in training and test set.

\section{Feature extraction}\label{sec:featuex}
As mentioned in section \ref{features}, a good classifier is depended of good features. In the section \ref{feature_extraction} has shown that mostly of previous work have been extracting features both in time domain and frequency domain. In this thesis will also be looking on both domains.
\\
\\
Figure \ref{fig:meanxyz} showing the mean of 10 samples in x,y and z-direction in time domain. Looking on figures \ref{fig:meanx} and \ref{fig:meanz}, floor and soft mat are the terrains which differ the most and should be easy to predict. Even shapes of curves to the floor is similar the carpet, the force in x- and z-direction is higher for the floor. While carpet and hard mat differ from its shapes of curve, but has the most similar values, which might be the most difficulty to discriminate. 
\\
\\
A mean of 10 samples in frequency domain is shown in figure \ref{fig:fftxyz}. The floor differ from the other in z-direction as seen in figure \ref{fig:fftz}, while the soft mat differ the most in x-direction shown in figure \ref{fig:fftx}. Again, carpet and hard mat has similar values.


\begin{comment}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meanx}
\caption{Figure showing force in the x-direction}
\label{fig:meanx2}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meany}
\caption{Figure showing force in the y-direction}
\label{fig:optoforce}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meanz}
\caption{Figure showing force in the z-direction}
\label{fig:optoforce}
\end{figure}
\end{comment}

\begin{figure} [h]
	\centering
	\begin{subfigure}[b]{0.95\textwidth}
		\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meanx}
		\caption{Mean of 10 samples in x-direction}
		\label{fig:meanx} 
	\end{subfigure}
	
	\begin{subfigure}[b]{0.95\textwidth}
		\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meany}
		\caption{Mean of 10 samples in y-direction}
		\label{fig:meany}
	\end{subfigure}
\end{figure}
	\begin{figure}[h] \ContinuedFloat
	\begin{subfigure}[b]{0.95\textwidth}
		\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/meanz}
		\caption{Mean of 10 samples in z-direction}
		\label{fig:meanz}
	\end{subfigure}
	
	\caption[]{The figure showing the mean of each terrain different direction in time domain. (a) mean in the x-direction (b) mean in y-direction (c) in z-direction }
	\label{fig:meanxyz}
\end{figure}


\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.95\textwidth}
		\includegraphics[width=1\linewidth]{Figures/fftx}
		\caption{Mean of 10 samples in x-direction}
		\label{fig:fftx} 
	\end{subfigure}
\end{figure}
\begin{figure}[h] \ContinuedFloat	
	\begin{subfigure}[b]{0.95\textwidth}
		\includegraphics[width=1\linewidth]{Figures/ffty}
		\caption{Mean of 10 samples in y-direction}
		\label{fig:ffty}
	\end{subfigure}


	\begin{subfigure}[h]{0.95\textwidth}
		\includegraphics[width=1\linewidth]{Figures/fftz}
		\caption{Mean of 10 samples in z-direction}
		\label{fig:fftz}
	\end{subfigure}
	
	\caption[]{The figure showing the mean of each terrain different direction in frequency domain. (a) mean in the x-direction (b) mean in y-direction (c) in z-direction}
	\label{fig:fftxyz}
\end{figure}
\FloatBarrier

\begin{comment}
\begin{figure}[h]
	\begin{subfigure}{0.5\linewidth}
		\centering
		\includegraphics[scale=0.42]{Figures/meanx}
		\caption{}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\linewidth}
		\centering
		\includegraphics[scale=0.42]{Figures/meany}
		\caption{}
		\label{fig:sub2}
	\end{subfigure}\\[1ex]
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[scale=0.42]{Figures/meanz}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\caption{Figur showing the mean}
	\label{fig:meanx}
\end{figure}
\end{comment}



\begin{comment}
	content...
\begin{figure}[h]
	\begin{subfigure}{0.5\linewidth}
		\centering
		\includegraphics[scale=0.4]{Figures/fftx}
		\caption{}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\linewidth}
		\centering
		\includegraphics[scale=0.4]{Figures/fftx}
		\caption{}
		\label{fig:sub2}
	\end{subfigure}\\[1ex]
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[scale=0.4]{Figures/fftx}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\caption{FFT of }
	\label{fig:fft}
\end{figure}
\end{comment}




\subsection{Feature sets}\label{sec:featuresets}
\paragraph{Feature set one - raw data} This feature set use all of the data from each step in x,y and z-direction. The raw data is decimated in order to achieve a constant length, in this case 125, and compressed into one feature vector. Achieving the fixed length is described in next section \ref{subseq:FixLength}. The feature vector will be:

\begin{equation} \label{eq:f1}
f_{set1}= \left\{ x_1,\dotsc,x_{125},y_1, \dotsc,y_{125},z_1,\dotsc,z_{125} \right\}
\end{equation}
The vector contain 125 feature from each 3 sensors, which mean 375 features.


\paragraph{Feature set two - statistical features} This feature set extracting statistical feature from the dataset. As mentioned in section \ref{sub:relatedfeatures} that many early work has been extracting the features with statistical metrics. Thus, the thesis will be using similar features. Calculation of some of statistical metrics are described in section \ref{sub:statical}. The features from this set will be for each direction x,y and z: 

%This is using some of the features from this article \cite{Hoffmann20141790}. 

\begin{enumerate}
\item The maximum value of the dataset in time domain
\item The minimum value of the dataset in time domain
\item Skew in time domain
\item Kurtosis in time domain 
\item Standard deviation in time domain
\end{enumerate}

The feature set will be look like:

\begin{align}
 f_{set2} &= \left\{ x_{max},x_{min},x_{skew},x_{kuortosis},x_{std},x_{var},x_{trapz}, \right.\nonumber\\
 &\qquad \left. {} y_{max},y_{min},y_{skew},y_{kuortosis},y_{std},y_{var},y_{trapz}, \right.\nonumber\\
 &\qquad \left. {} z_{max},z_{min},z_{skew},z_{kuortosis},z_{std},z_{var},z_{trapz} \right\}
\end{align}
The vector contain 5 features from each direction, which is in total 15 features. 

\paragraph{Feature set three - complete frequency spectrum} Previous work has shown that using frequency has shown good result. In this feature set, the raw data from time domain is transformed into the frequency domain by fast Fourier transform. After transformation a decimation is used to achieve a fixed length. Since the minimum of length in time domain is 125, and the fast Fourier transform is symmetric, the minimum length of entire spectrum will be 62.5, however in this approach will be decimating it to a length of 61. Only data at the end of sequence, since it is considered as less important than in front. 
 

\begin{equation} \label{eq:f2}
f_{set3}= \left\{ fx_1,\dotsc,fx_{61},fy_1, \dotsc,fy_{61},fz_1,\dotsc,fz_{61} \right\}
\end{equation}
The vector contain 61 features from each direction, which is in total 183 features. 

\paragraph{Feature set four - staticial features} This feature set compute the statistical metrics similar to feature set two, but in frequency domain. Additionally the energy of the spectrum suggested in \cite{26b23e912c654fe4b7478fd910130195}, by calculating the sum of the squares of the amplitudes is also used.

\begin{enumerate}
\item The maximum value of the dataset in frequency domain
\item The minimum value of the dataset in frequency domain
\item Skew in frequency domain
\item Kurtosis in frequency domain 
\item Standard deviation in frequency domain
\item Energy 
\end{enumerate}
The feature which will be feed into classifier:
\begin{align}
 f_{set3} &= \left\{ fx_{max},fx_{min},fx_{skew},fx_{kuortosis},fx_{std},fx_{var},fx_{E}, \right.\nonumber\\
 &\qquad \left. {} fy_{max},fy_{min},fy_{skew},fy_{kuortosis},fy_{std},fy_{var},fy_{E}, \right.\nonumber\\
 &\qquad \left. {} fz_{max},fz_{min},fz_{skew},fz_{kuortosis},fz_{std},fz_{var},fz_{E} \right\}
\end{align}
The vector contain 6 features from each direction, which is in total 18 features. 

\paragraph{Feature set five - set two and four} Good feature might come from different feature sets. The features from set two and four will be collected as a one set. 
\begin{align}
f_{set5} &= \left\{ x_{max},x_{min},x_{skew},x_{kuortosis},x_{std},x_{var},x_{trapz}, \right.\nonumber\\
&\qquad \left. {}  y_{max},y_{min},y_{skew},y_{kuortosis},y_{std},y_{var},y_{trapz}, \right.\nonumber\\
&\qquad \left. {}  z_{max},z_{min},z_{skew},z_{kuortosis},z_{std},z_{var},z_{trapz}, \right.\nonumber\\
&\qquad \left. {} fx_{max},fx_{min},fx_{skew},fx_{kuortosis},fx_{std},fx_{var},fx_{E}, \right.\nonumber\\
&\qquad \left. {} fy_{max},fy_{min},fy_{skew},fy_{kuortosis},fy_{std},fy_{var},fy_{E}, \right.\nonumber\\
&\qquad \left. {} fz_{max},fz_{min},fz_{skew},fz_{kuortosis},fz_{std},fz_{var},fz_{E} \right\}
\end{align}
The vector contain 13 features from each direction, which is in total 39 features. 

\subsection{Achieving a fixed length of the sequences} \label{subseq:FixLength}
In order to use raw data as input, an fixed length is required. The steps have been decimated in order for to achieve a constant length of 125. It is shown that each step is vary between 125-135. A simplified method for achieving fixed length is shown. Note the technique is simplified to one-dimensional array, while in thesis has 3 dimensional array, but the intention is same. Using this technique it is considered that data in end and start are less important than in middle.
  
\begin{lstlisting}[language=Python]

def fix_length(data_sequence):
    fixed_length = 125
    total_length = len(data_sequence)  

    #Total amount data to be removed
    total_cut = total_length-fixed_length

    #In case the sequence is odd
    rest = total_cut%2
    
    #Calculate the start and end position
    start_pos = total_cut/2 
    end_pos = total_length - (total_cut/2)+rest 

    #Retrieve fixed length of sequense data 
    fixed_data_sequence = data_sequence[start_pos:end_pos] 
    return fixed_data_sequence
\end{lstlisting}

\newpage
\section{Learning approach}
The learning approach is divided into to processes. First to divide the file and learning process.

\subsection{Collecting samples}
The samples used as training and test is a step before the learning procedure. This is to gather data sample for each terrain into a file, which will be used in the learning process. The procedure is shown in figure \ref{fig:createsamples}

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[scale=0.7,transform shape]
	
	% Draw diagram elements
	\path \io{1}{Raw data};
	
	\path (p1.south)+(0,-1.5) \etape{2}{Extract steps};
	\path (p2.south)+(0.0,-1.5) \etape{3}{Write to file};
	

	%  \node [below=of p5] (p6-7) {};
	
	% Draw arrows between elements
	\path [line] (p1.south) -- node [above] {} (p2);
	\path [line] (p2.south) -- node [above] {} (p3);
	\end{tikzpicture}

\caption{The figure showing process of creating training file.} \label{fig:createsamples}
\end{figure}

\subsubsection{Procedure of creating samples} \label{sub:createsamples}
\begin{enumerate}
	\item \textbf{\underline{Raw data}}
	\\
	The dataset is retrieved from the optical force sensor.
	
	\item \textbf{\underline{Extract steps}}
	\\
	Raw data will be partitioned into samples as described in section \ref{subseq:segmentation}.
	
	\item \textbf{\underline{Write to file}}
	\\
	This step will write each of data sequence into file with label of the terrain name.
	

\end{enumerate}
\clearpage
\subsection{Learning procedure}
When the data samples of each terrain is collected into a file, the learning process is shown in figure \ref{fig:learningProcess}.
\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=0.7,transform shape]

  % Draw diagram elements
  
  \path \etape{2}{Read file};
  \path (p2.south)+(0.0,-1.5) \etape{3}{Extract features};

  \path (p3.south)+(0.0,-1.5) \etape{4}{Split data};
  \path (p4.south)+(8,-2.0) \etape{5}{Scaling};
  \path (p5.south)+(0,-1.8) \etape{6}{Model};
  \path (p4.south)+(0,-3.3) \etape{9}{Scaling};
  \path (p9.south)+(0,-4.0) \etape{7}{Test classifier};
  
  \path (p7.south)+(0,-1.5) \etape{10}{Store result};
  \path (p10.south)+(0,-1.5) \etape{8}{Result};
    
%  \node [below=of p5] (p6-7) {};

  % Draw arrows between elements
 
  \path [line] (p2.south) -- node [above] {} (p3);
  \path [line] (p3.south) -- node [above] {} (p4);
  \path [line] (p4.south) -| node [above] {Training set} (p5);
    
  \path [line] (p5.south) -- node [above] {} (p6);
  \path [line] (p6.south) |- node [above] {} (p7);
  \path [line] (p4.south) -- node [right] {Test set} (p9);
  \path [line] (p7.south) -- node [above] {} (p10);
  \path [line] (p10.south) -- node [above] {} (p8);
  \path [line] (p9.south) -- node [above] {} (p7);
%  \path [line] (p5.south) -- node [above] {Feature} (p9);
   \path [line,dashed] (p5) -- node [above]{Scaling factors} (p9);
  \background{p3}{p4}{p5}{p10}{Loop} 
  
\end{tikzpicture}



\caption{Figure showing the steps in creating a model and obtain a result.} \label{fig:learningProcess}
\end{figure}

\FloatBarrier
\clearpage
\subsubsection{Details of the learning process}
\begin{enumerate}
\item \textbf{\underline{Reading file with samples}}
\\
This step will take a file as input, created from section \ref{sub:createsamples}.

\item \textbf{\underline{Extract features}}
\\
This step will create one of the five feature sets as mentioned in section \ref{sec:featuresets}.

\item \textbf{\underline{Loop}}

\begin{enumerate} 
\item \textbf{\underline{Split data}} \label{en:loop}
\\
\\
The extracted feature vectors is partitioned into a training and testing set. The cross validation is LOOCV, thus the training set consists of 199 samples and one test sample.


\item \textbf{\underline{Scaling}}
\\
This step takes the training set as input and standardization as mention in section \ref{subsec:scaling}. It will first scale the training data, and then scaling factors are applied to the test data.

Scale first the training set and then transform the testing set.
\item \textbf{\underline{Train the classifier}}
\\
The classifier will take the training set as input and train.

\item \textbf{\underline{Test classifier}} This step use the model to predict the test set. It will store the score.


\item \textbf{\underline{Store result}} This step will store the result of the test sample.If there are still more data to be predicted start from \ref{en:loop}.

\end{enumerate}


\item \textbf{\underline{Result}}
\\
\\
Compute the average results as mentioned in section \ref{subsec:evalclf} 
\end{enumerate}



\chapter{Experiments and results}                     %% ... or ??
The chapter present the results of all model in previous chapter. The two-class classification will be investigated first. Further will be to using methods to improve each of classifier. The best classifier will be used to test. 

\section{Results of classifier}\label{result_exp1}
Table \ref{exp1} shows the result when using the learning approach. The accuracy is the average accuracy. The experiments were done once, both with and without the feature scaling. 


\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}llll@{}}
			\toprule
			\multirow{2}{*}{\textbf{Feature set}} & \multirow{2}{*}{\textbf{Classifier}} & \multicolumn{2}{c}{\textbf{Accuracy}} \\ \cmidrule(l){3-4} 
			&  & \multicolumn{1}{l|}{\textbf{Not scaled}} & \textbf{Scaled} \\ \midrule
			\multicolumn{1}{l|}{\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Set one -\\ raw data\end{tabular}}} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{83\%} & 83\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{94\%} & 96\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{89\%} & 91\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{95\%} & 96\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{89\%} & 93\% \\ \midrule
			\multicolumn{1}{l|}{\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Set two - \\ statistical features in \\ time domain\end{tabular}}} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{82\%} & 82\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{83\%} & 84\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{84\%} & 84\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{83\%} & 88\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{76\%} & 85\% \\ \midrule
			\multicolumn{1}{l|}{\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Set three - \\ complete frequency \\ domain\end{tabular}}} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{91\%} & 91\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{83\%} & 82\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{91\%} & 88\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{93\%} & 93\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{52\%} & 93\% \\ \midrule
			\multicolumn{1}{l|}{\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Set four - \\ staticial features in \\ frequency domain\end{tabular}}} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{81\%} & 81\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{80\%} & 82\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{88\%} & 84\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{85\%} & 88\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{83\%} & 86\% \\ \midrule
			\multicolumn{1}{l|}{\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Set five - \\ set 2,4\end{tabular}}} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{82\%} & 82\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{79\%} & 80\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{88\%} & 84\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{87\%} & 89\% \\ \cmidrule(l){2-4} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{83\%} & 86\% \\ \bottomrule
		\end{tabular}%
	}
	\caption{Table showing the result after following the approach shown in figure \ref{fig:learningProcess}}
	\label{exp1}
\end{table}


\FloatBarrier


\subsection{Analysis}
The result shown that all classifier has a accuracy at least 70\%. The Decision tree and Neural Network has the highest accuracy with 96\% from scaled feature set one. 
\\
\\
Regarding the feature scaling, SVM classifer is the one with huge affect of the scaled. The KNN which is also distances is also affected by scaling, but most of them gave lesser accuracy. While Neural Network, Decision tree and Bayes Navies do not rely on distance between features, only Bayes Navies was not affected. The Neural Network and Decision Tree had minor change in their accuracy. Since the feature scaling had great affect on the SVM and minor on the other classifier, scaled features will be used in further experiments.
\\
\\
Among the highest result is either from whole raw data sequence or complete frequency domain. These type of features has the benefit of ensuring that all the information is in the data. However, too many features has a risk learning from noises, and lead to overfitting as mentioned in section \ref{curseDim}.



\section{Further improving all classifier}
Even there are classifier which outperform the other, there are still improvement potential. In the previous approach, the feature selection was not taken in account. The purpose of not using the feature selection was to see the performance without loosing any features. In following experiment, the feature selection will be applied to see if there any improvement.  In this approach feature selection is integrated into previous implementation. The filter and wrapper method will be used. Both is library provided by scikit. The filter method will be removing features with low variance, while the wrapper method is recursive feature elimination. Figure \ref{fig:approach2}



\begin{figure}[h!]
\centering
\begin{tikzpicture}[scale=0.7,transform shape]

  % Draw diagram elements
%  \path \io{1}{Raw data};
  \path \io{2}{Read file};
%  \path (p1.south)+(0,-1.5) \etape{2}{Extract steps};
  \path (p2.south)+(0.0,-1.5) \etape{3}{Extract features};
  \path (p3.south)+(0.0,-1.5) \etape{11}{Feature selection};
  
  \path (p11.south)+(0.0,-1.5) \etape{4}{Split data};
  \path (p4.south)+(8,-2.0) \etape{5}{Scaling};
  \path (p5.south)+(0,-1.8) \etape{6}{Model};
  \path (p4.south)+(0,-3.3) \etape{9}{Scaling};
  \path (p9.south)+(0,-4.0) \etape{7}{Test classifier};
  
  \path (p7.south)+(0,-1.5) \etape{10}{Store result};
  \path (p10.south)+(0,-1.5) \etape{8}{Result};
    
%  \node [below=of p5] (p6-7) {};

  % Draw arrows between elements
 % \path [line] (p1.south) -- node [above] {} (p2);
  \path [line] (p2.south) -- node [above] {} (p3);
  \path [line] (p3.south) -- node [above] {} (p11);
  \path [line] (p11.south) -- node [above] {} (p4);
  \path [line] (p4.south) -| node [above] {Training set} (p5);
    
  \path [line] (p5.south) -- node [above] {} (p6);
  \path [line] (p6.south) |- node [above] {} (p7);
  \path [line] (p4.south) -- node [right] {Test set} (p9);
  \path [line] (p7.south) -- node [above] {} (p10);
  \path [line] (p10.south) -- node [above] {} (p8);
  \path [line] (p9.south) -- node [above] {} (p7);
%  \path [line] (p5.south) -- node [above] {Feature} (p9);
   \path [line,dashed] (p5) -- node [above]{Scaling factors} (p9);
  \background{p3}{p4}{p5}{p7}{Loop} 
  
\end{tikzpicture}

\caption{Figure showing the new approach with added feature selection.} \label{fig:approach2}
\end{figure}


\section{Experiment 2 - classifier improvement}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}lllll@{}}
			\toprule
			&  & \multicolumn{3}{c}{\textbf{Accuracy}} \\ \cmidrule(l){3-5} 
			\multirow{-2}{*}{\textbf{Feature set}} & \multirow{-2}{*}{\textbf{Classifier}} & \multicolumn{1}{l|}{\textbf{Old result}} & \multicolumn{1}{l|}{\textbf{Filter}} & \textbf{Wrapper} \\ \midrule
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{83\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 78\%}} & {\color[HTML]{FE0000} 81\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Decision tree}} & \multicolumn{1}{l|}{\textbf{96\%}} & \multicolumn{1}{l|}{\textbf{96\%}} & {\color[HTML]{FE0000} 93\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{91\%} & \multicolumn{1}{l|}{{\color[HTML]{009901} 95\%}} & {\color[HTML]{009901} 93\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Neural network}} & \multicolumn{1}{l|}{\textbf{96\%}} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 94\%}} & {\color[HTML]{FE0000} 95\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{\multirow{-5}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Set one -\\ raw data\end{tabular}}}} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{93\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 91\%}} & {\color[HTML]{009901} 94\%} \\ \midrule
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 74\%}} & {\color[HTML]{009901} 84\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{84\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 79\%}} & {\color[HTML]{FE0000} 81\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{84\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 82\%}} & {\color[HTML]{FE0000} 82\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 81\%}} & {\color[HTML]{FE0000} 84\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{\multirow{-5}{*}{\begin{tabular}[c]{@{}l@{}}Set two - \\ statistical features in \\ time domain\end{tabular}}} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{85\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 80\%}} & {\color[HTML]{FE0000} 83\%} \\ \midrule
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{91\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 76\%}} & {\color[HTML]{FE0000} 94\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 76\%}} & {\color[HTML]{FE0000} 81\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 83\%}} & 88\% \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{93\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 78\%}} & {\color[HTML]{009901} 94\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{\multirow{-5}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Set three - \\ complete frequency \\ domain\end{tabular}}}} & \multicolumn{1}{l|}{\textbf{SVM}} & \multicolumn{1}{l|}{93\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 79\%}} & {\color[HTML]{009901} \textbf{97\%}} \\ \midrule
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{81\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 75\%}} & {\color[HTML]{FE0000} 79\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{82\%} & {\color[HTML]{FE0000} 81\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{KNN} & \multicolumn{1}{l|}{84\%} & \multicolumn{1}{l|}{{\color[HTML]{009901} 85\%}} & {\color[HTML]{009901} 86\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 84\%}} & {\color[HTML]{009901} 90\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{\multirow{-5}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Set four - \\ staticial features in \\ frequency domain\end{tabular}}}} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 82\%}} & {\color[HTML]{009901} 86\%} \\ \midrule
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Bayes Navies} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 74\%}} & {\color[HTML]{009901} 84\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Decision tree} & \multicolumn{1}{l|}{80\%} & \multicolumn{1}{l|}{{\color[HTML]{009901} 82\%}} & {\color[HTML]{009901} 82\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{KNN}} & \multicolumn{1}{l|}{84\%} & \multicolumn{1}{l|}{{\color[HTML]{009901} 86\%}} & {\color[HTML]{009901} \textbf{86\%}} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Neural network} & \multicolumn{1}{l|}{89\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 81\%}} & {\color[HTML]{FE0000} 85\%} \\ \cmidrule(l){2-5} 
			\multicolumn{1}{l|}{\multirow{-5}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Set five - \\ set 2,4\end{tabular}}}} & \multicolumn{1}{l|}{SVM} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{{\color[HTML]{FE0000} 83\%}} & {\color[HTML]{009901} 84\%} \\ \bottomrule
		\end{tabular}%
	}
	\caption{Table showing the results after following integrating  feature selection to the learning approach}
	\label{tab:exp2}
\end{table}

\FloatBarrier

\section{Analysis}
From table \ref{tab:exp2} one can see that the filter selection has made most of the classifier more inaccurate. Only neural network and decision tree with feature set one which has shown some improvement. This may indicate that important features were removed. The wrapper selection, on the other hand, also have some classifier which performed less accurately, but the difference between old result is less than filter. Some of classifier has improved significant, particularly the SVM with feature set three with 97\% accuracy.
\\
\\
Note that the k-fold validation test using always use the same single set both for training and testing, which make it referring to themselves has the risk of not generalizing the classifier. In this case results from \ref{tab:exp2} only gives an estimation on how well a classifier is, but does not tell how well it predict on unseen data. One way to avoid this issue is make the training and testing set independent to each other, so the prediction will be based on new and unseen data \cite{26b23e912c654fe4b7478fd910130195}. The following experiment will be using two highest performed classifier shown in \ref{tab:exp2}. As there are three shared second best classifier, all of them will be in further experiments. Additionally, KNN using wrapper method with feature set five achieved a satisfied result which will also be further investigated. The reason is among the four best performed classifier is only using either the entire raw data or frequency domain. Thus, it will be interesting to compare a classifier with extracted features.

\section{Cross validation with unseen data} \label{seq:crossunseen}
In this experiment 50 new samples for each terrain is collected. In the cross validation it will use the old dataset as training set, while the new collected samples will be used as test file. The cross validation is still LOOCV. The training and test set will be randomly shuffled before the cross validation. Thus, to achieve more precise measurement, each test will be running five times.

\begin{enumerate}
\item SVM with wrapper and use feature set two
\item Neural Network and use feature set one.
\item Decision tree with feature set one
\item Decision tree with filter and use feature set one
\item KNN with wrapper and feature set five
\end{enumerate}


\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cmidrule(l){3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{94\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{0} & 41 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{97\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{0} & 47 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{94\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{0} & 41 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{94\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{0} & 40 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{97\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{0} & 47 \\ \bottomrule
	\end{tabular}
	\caption{Table showing the accuracy and confusion matrix for SVM with wrapper and feature set two. The row show the actual terrains and the columns is predicted terrain}
	\label{svmexp}
\end{table}
\FloatBarrier
\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{96\%} & \multicolumn{1}{l|}{96\%} & \multicolumn{1}{l|}{96\%} & 96\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{80\%} & 94\% \\ \bottomrule
	\end{tabular}
	\caption{Table shows precision of SVM}
	\label{pressvm}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{90.9\%} & \multicolumn{1}{l|}{92.6\%} & \multicolumn{1}{l|}{92.6\%} & \multicolumn{1}{l|}{92.6\%} & 92.6\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{87\%} & \multicolumn{1}{l|}{98\%} & \multicolumn{1}{l|}{87.2\%} & \multicolumn{1}{l|}{85.7\%} & 98\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \bottomrule
	\end{tabular}
	\caption{Table shows recall of SVM}
	\label{recallsvm}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{95.2\%} & \multicolumn{1}{l|}{96.2\%} & \multicolumn{1}{l|}{96.2\%} & \multicolumn{1}{l|}{96.2\%} & 96.2\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{90.4\%} & \multicolumn{1}{l|}{97\%} & \multicolumn{1}{l|}{91.4\%} & \multicolumn{1}{l|}{90.6\%} & 97\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{90.1\%} & \multicolumn{1}{l|}{96.9\%} & \multicolumn{1}{l|}{90.1\%} & \multicolumn{1}{l|}{88\%} & 96.9\% \\ \bottomrule
	\end{tabular}
	\caption{Table shows f-score of SVM}
	\label{fscoresvm}
\end{table}
\FloatBarrier
\subsubsection{SVM - Wrapper - Feature set two}
On the table \ref{svmexp} showing accuracy. The average is at least 94\%, and has the average 95.2\%. It can be seen that classifier simple distinguish floor and soft mat, while the carpet has a little confusion, and the hard mat is more confused. As seen in table \ref{fscoresvm} the soft mat has a f-score on 100\%, which means high precision and recall. Floor is second highest f-score with average 96\%. The recall is the reason of decreased f-score. The hard mat and carpet has relative equally f-score. However the carpet got a lower recall, but higher precision, while the hard mat got higher recall, but lower precision. 


\begin{comment}
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}llllllllll@{}}
			\toprule
			\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Terrain}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} & \multirow{2}{*}{\textbf{Precision}} & \multirow{2}{*}{\textbf{Recall}} & \multirow{2}{*}{\textbf{F-score}} & \multirow{2}{*}{\textbf{Accuracy}} \\ \cmidrule(lr){3-6}
			&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} &  &  &  &  \\ \midrule
			\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & 0.94 \\ \cmidrule(l){2-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){2-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){2-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \midrule
			\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{p2}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & 0.97 \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \midrule
			\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{p3}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & 0.94 \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \midrule
			\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{p4}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & 0.94 \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{40} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \midrule
			\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{p5}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & 0.97 \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \cmidrule(l){3-10} 
			\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  \\ \bottomrule
		\end{tabular}%
	}
	\caption{My caption}
	\label{my-label}
\end{table}
\end{comment}

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cmidrule(l){3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{68\%}} & \multicolumn{1}{l|}{25} & \multicolumn{1}{l|}{25} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{49} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{11} & \multicolumn{1}{l|}{28} & \multicolumn{1}{l|}{0} & 11 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{68\%}} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{24} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{9} & \multicolumn{1}{l|}{30} & \multicolumn{1}{l|}{0} & 11 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{64\%}} & \multicolumn{1}{l|}{20} & \multicolumn{1}{l|}{30} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 2 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{11} & \multicolumn{1}{l|}{29} & \multicolumn{1}{l|}{0} & 10 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{68\%}} & \multicolumn{1}{l|}{27} & \multicolumn{1}{l|}{23} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{49} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{9} & \multicolumn{1}{l|}{32} & \multicolumn{1}{l|}{0} & 9 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{69\%}} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{24} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{49} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{10} & \multicolumn{1}{l|}{28} & \multicolumn{1}{l|}{0} & 12 \\ \bottomrule
	\end{tabular}
	\caption{Neural network - Feature set 1 without selection}
	\label{nn2}
\end{table}
\FloatBarrier
\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{50\%} & \multicolumn{1}{l|}{52\%} & \multicolumn{1}{l|}{40\%} & \multicolumn{1}{l|}{54\%} & 52\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{98\%} & \multicolumn{1}{l|}{96\%} & \multicolumn{1}{l|}{96\%} & \multicolumn{1}{l|}{98\%} & 98\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{22\%} & \multicolumn{1}{l|}{22\%} & \multicolumn{1}{l|}{20\%} & \multicolumn{1}{l|}{18\%} & 24\% \\ \bottomrule
	\end{tabular}
	\caption{Precision Neural Network}
	\label{nnPrecision}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{67.6\%} & \multicolumn{1}{l|}{72.2\%} & \multicolumn{1}{l|}{64.5\%} & \multicolumn{1}{l|}{75\%} & 72.2\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{48\%} & \multicolumn{1}{l|}{47.1\%} & \multicolumn{1}{l|}{44.9\%} & \multicolumn{1}{l|}{47\%} & 48.5\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{91.7\%} & \multicolumn{1}{l|}{83.3\%} & \multicolumn{1}{l|}{90\%} & 92.3\% \\ \bottomrule
	\end{tabular}
	\caption{Neural network recall}
	\label{nnrecall}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{57.5\%} & \multicolumn{1}{l|}{60.5\%} & \multicolumn{1}{l|}{49.4\%} & \multicolumn{1}{l|}{62.8\%} & 60.5\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{64.4\%} & \multicolumn{1}{l|}{63.2\%} & \multicolumn{1}{l|}{61.2\%} & \multicolumn{1}{l|}{63.5\%} & 64.9\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{36.1\%} & \multicolumn{1}{l|}{35.5\%} & \multicolumn{1}{l|}{32.3\%} & \multicolumn{1}{l|}{30\%} & 38.1\% \\ \bottomrule
	\end{tabular}
	\caption{Neural network fscore}
	\label{nnfscore}
\end{table}
\FloatBarrier

\subsubsection{Neuarl Network - Feature set one}
On the table \ref{nn2} showing accuracy. Compared to the old result from \ref{tab:exp2} with accuracy on 96\%, the classifier perform more poorly on unseen data, with average accuracy 67.4\%. The classifier has most difficulty of distinguish the hard mat, but do have some problems with floor too. The soft mat is the easiest terrain to predict with f-score on 100\%, shown in \ref{nnfscore}. Carpet is second highest f-score with average... Even the precision is high, but the recall is low. Third highest f-score is floor. Recall and precision is factor which lead to low f-score. The least highest f-score is the hard mat with average... The recall is relative high, but the precision is low, which make a low f-score.


\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cmidrule(l){3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{72\%}} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{2} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{4} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{2} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{46} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{2} & 14 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{73\%}} & \multicolumn{1}{l|}{45} & \multicolumn{1}{l|}{4} & \multicolumn{1}{l|}{1} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{38} & \multicolumn{1}{l|}{2} & 5 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{47} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{24} & \multicolumn{1}{l|}{1} & 17 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{75\%}} & \multicolumn{1}{l|}{44} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{3} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{47} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{0} & 17 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{72\%}} & \multicolumn{1}{l|}{44} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{4} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{46} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{27} & \multicolumn{1}{l|}{1} & 14 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{77\%}} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{2} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{39} & \multicolumn{1}{l|}{2} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{49} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{21} & \multicolumn{1}{l|}{3} & 18 \\ \bottomrule
	\end{tabular}
	\caption{ecision tree precision without filter}
	\label{dt1e}
\end{table}
\FloatBarrier
\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{90\%} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{88\%} & 96\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{76\%} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{82\%} & 78\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{92\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{92\%} & 98\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{28\%} & \multicolumn{1}{l|}{34\%} & \multicolumn{1}{l|}{34\%} & \multicolumn{1}{l|}{28\%} & 36\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree precision without filter}
	\label{dt1Precision}
\end{table}
\FloatBarrier
\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{78.1\%} & \multicolumn{1}{l|}{77.6\%} & \multicolumn{1}{l|}{78.6\%} & \multicolumn{1}{l|}{75.9\%} & 78.7\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{56.9\%} & \multicolumn{1}{l|}{57.6\%} & \multicolumn{1}{l|}{58.6\%} & \multicolumn{1}{l|}{58.6\%} & 65\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{88.5\%} & \multicolumn{1}{l|}{92.2\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{90.2\%} & 87.5\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{66.7\%} & \multicolumn{1}{l|}{68\%} & \multicolumn{1}{l|}{70.8\%} & \multicolumn{1}{l|}{66.7\%} & 78.3\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree recall without filter}
	\label{dt1recall}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{81.9\%} & \multicolumn{1}{l|}{83.3\%} & \multicolumn{1}{l|}{83\%} & \multicolumn{1}{l|}{81.5\%} & 86.5\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{67.2\%} & \multicolumn{1}{l|}{65.5\%} & \multicolumn{1}{l|}{68.4\%} & \multicolumn{1}{l|}{68.4\%} & 70.9\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{90.2\%} & \multicolumn{1}{l|}{93.1\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{92\%} & 92.5\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{39.4\%} & \multicolumn{1}{l|}{45.3\%} & \multicolumn{1}{l|}{45.9\%} & \multicolumn{1}{l|}{39.4\%} & 49.3\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree fscore without filter}
	\label{dtfscore}
\end{table}
\FloatBarrier

\subsubsection{Decision Tree - Feature set one}
On the table \ref{dt1e} showing accuracy. Comparing to the old result from \ref{tab:exp2}, the classifier perform more poorly on unseen data. Again, the soft mat is the easiest terrain to recognize, and has the highest f-score. There is confusion when it is on hard mat. It is confused by hard mat and carpet. However, when there is less confusion when the robot is on carpet. When it is on hard mat, the classifier tend to predict carpet than hard mat. That is what make carpet have a hight precision, but low recall. However, the hard mat has a higher recall, but lower precision.  

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cmidrule(l){3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{73\%}} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{2} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{39} & \multicolumn{1}{l|}{1} & 5 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{44} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{1} & 16 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{75\%}} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{47} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{28} & \multicolumn{1}{l|}{0} & 14 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{75\%}} & \multicolumn{1}{l|}{44} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{3} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{5} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{47} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{26} & \multicolumn{1}{l|}{0} & 17 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{73\%}} & \multicolumn{1}{l|}{45} & \multicolumn{1}{l|}{4} & \multicolumn{1}{l|}{0} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & 3 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{45} & 2 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{27} & \multicolumn{1}{l|}{0} & 15 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{72\%}} & \multicolumn{1}{l|}{45} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{3} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{40} & \multicolumn{1}{l|}{0} & 4 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{47} & 2 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{32} & \multicolumn{1}{l|}{0} & 12 \\ \bottomrule
	\end{tabular}
	\caption{Decision tree}
	\label{dt4}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{90\%} & 90\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{78\%} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{82\%} & \multicolumn{1}{l|}{82\%} & 80\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{88\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{90\%} & 94\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{32\%} & \multicolumn{1}{l|}{28\%} & \multicolumn{1}{l|}{34\%} & \multicolumn{1}{l|}{30\%} & 24\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree filter - precision}
	\label{dtfilterprecision}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{79.7\%} & \multicolumn{1}{l|}{77\%} & \multicolumn{1}{l|}{78.6\%} & \multicolumn{1}{l|}{76.3\%} & 78.9\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{56.5\%} & \multicolumn{1}{l|}{55.4\%} & \multicolumn{1}{l|}{58.6\%} & \multicolumn{1}{l|}{54.7\%} & 53.3\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{91.7\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{100\%} & 94\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{66.7\%} & \multicolumn{1}{l|}{77.8\%} & \multicolumn{1}{l|}{70.8\%} & \multicolumn{1}{l|}{65.2\%} & 66.7\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree filter recall}
	\label{dtfilterrecall}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{86.3\%} & \multicolumn{1}{l|}{84.7\%} & \multicolumn{1}{l|}{83\%} & \multicolumn{1}{l|}{82.6\%} & 84.1\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{65.5\%} & \multicolumn{1}{l|}{66.1\%} & \multicolumn{1}{l|}{68.4\%} & \multicolumn{1}{l|}{65.6\%} & 64\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{89.8\%} & \multicolumn{1}{l|}{96.9\%} & \multicolumn{1}{l|}{94\%} & \multicolumn{1}{l|}{94.7\%} & 94\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{43.3\%} & \multicolumn{1}{l|}{41.2\%} & \multicolumn{1}{l|}{45.9\%} & \multicolumn{1}{l|}{41.1\%} & 35.3\% \\ \bottomrule
	\end{tabular}
	\caption{Decision tree filter fscore}
	\label{dtfilterfscore}
\end{table}
\FloatBarrier
\subsubsection{Decision Tree - Filter - Feature set one}
Comparing the new result from table \ref{dt4} to the old result from \ref{tab:exp2}, the classifier perform more poorly on unseen data. Again, the soft mat is the easiest terrain to recognize, and has the highest f-score. There is confusion when it is on hard mat, and the classifier has difficulty of decide wheter it is on hard mat or carpet. However there is less confusion when the robot is on the carpet.  That is what make carpet have a hight precision, but low recall. However, the hard mat has a higher recall, but lower precision.  



\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cmidrule(l){3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{81\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{22} & \multicolumn{1}{l|}{0} & 20 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{81\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{22} & \multicolumn{1}{l|}{0} & 20 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{81\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{22} & \multicolumn{1}{l|}{0} & 20 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{4}} & \multicolumn{1}{l|}{\multirow{4}{*}{81\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{22} & \multicolumn{1}{l|}{0} & 20 \\ \midrule
		\multicolumn{1}{l|}{\multirow{4}{*}{5}} & \multicolumn{1}{l|}{\multirow{4}{*}{81\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{0} & 1 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cmidrule(l){3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{22} & \multicolumn{1}{l|}{0} & 20 \\ \bottomrule
	\end{tabular}
	\caption{KNN }
	\label{knnexp}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{86\%} & \multicolumn{1}{l|}{86\%} & 86\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{40\%} & \multicolumn{1}{l|}{40\%} & \multicolumn{1}{l|}{40\%} & \multicolumn{1}{l|}{40\%} & 40\% \\ \bottomrule
	\end{tabular}
	\caption{Knn precision}
	\label{precisionKNN}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{78.1\%} & \multicolumn{1}{l|}{78.1\%} & \multicolumn{1}{l|}{78.1\%} & \multicolumn{1}{l|}{78.1\%} & 78.1\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{66.2\%} & \multicolumn{1}{l|}{66.2\%} & \multicolumn{1}{l|}{66.2\%} & \multicolumn{1}{l|}{66.2\%} & 66.2\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{95.2\%} & \multicolumn{1}{l|}{95.2\%} & \multicolumn{1}{l|}{95.2\%} & \multicolumn{1}{l|}{95.2\%} & 95.2\% \\ \bottomrule
	\end{tabular}
	\caption{KNN recall}
	\label{knnrecall}
\end{table}
\FloatBarrier

\begin{table}[h]
	\centering
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multirow{2}{*}{\textbf{Terrain}} & \multicolumn{5}{c}{\textbf{Run}} \\ \cmidrule(l){2-6} 
		& \multicolumn{1}{l|}{\textbf{1}} & \multicolumn{1}{l|}{\textbf{2}} & \multicolumn{1}{l|}{\textbf{3}} & \multicolumn{1}{l|}{\textbf{4}} & \textbf{5} \\ \midrule
		\multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{87.7\%} & \multicolumn{1}{l|}{87.7\%} & \multicolumn{1}{l|}{87.7\%} & \multicolumn{1}{l|}{87.7\%} & 87.7\% \\ \midrule
		\multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{74.8\%} & \multicolumn{1}{l|}{74.8\%} & \multicolumn{1}{l|}{74.8\%} & \multicolumn{1}{l|}{74.8\%} & 74.8\% \\ \midrule
		\multicolumn{1}{l|}{Soft mat} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & \multicolumn{1}{l|}{100\%} & 100\% \\ \midrule
		\multicolumn{1}{l|}{Hard mat} & \multicolumn{1}{l|}{56.3\%} & \multicolumn{1}{l|}{56.3\%} & \multicolumn{1}{l|}{56.3\%} & \multicolumn{1}{l|}{56.3\%} & 56.3\% \\ \bottomrule
	\end{tabular}
	\caption{KNN fscore}
	\label{knnfscore}
\end{table}
\FloatBarrier

\subsection{KNN - Wrapper - Feature set five}
Comparing the new result from table \ref{dt4} to the old result from table \ref{tab:exp2}, the accuracy has decreased a little. It is shown that the it is confused especially between the hard mat and carpet. When it is on the hard mat it rather predict as carpet. However, there is less confusion when the robot is on carpet and is more able to predict correct.

 
\subsection{Summary}
Five different classifier with different feature sets were investigated. Compared to the old result from table \ref{tab:exp2}, every classifier has decreased their accuracy. SVM still have the highest accuracy, even on predicting unseen data. KNN on other hand, which were least highest among those five tested classifiers were the second best on predicting unseen data. Neural network is the classifier with least accuracy. The decision tree with and without feature selection has relative equal accuracy.
\\
\\
It can be seen a common confusion for each classifiers when the robot is on hard mat. Mostly of classifiers tend to chose carpet instead of hard mat. This is also the reason that the f-score of carpet and hard mat is relative low, even there are high precision on predicting carpet on carpet. The least confusion is the soft mat, where the every classifier has a average over 90\%. The floor also achieved a high f-score, except for the neural network without filter. The neural network had issues to distinguish between floor and carpet. 



\section{Classification in real-time} \label{sec:realtime}
To get a more realistic practical scenario  is based on evaluation of the classification, where the robot traversing in different terrains. For this experiment, the robot will be walking on two different terrains. There are total five different setup. The uequal length of each steps is that the robot tend to walk out off current terrain, thus stops the experiments. 


\begin{enumerate}
\item Floor to carpet
\item Hard mat to floor
\item Hard mat to soft mat
\item Soft mat to hard mat
\item Soft mat to carpet
\end{enumerate}

\subsection{Real time implementation}
The real time implementation can be seen on figure \ref{fig:realtime}, which is a small modification of earlier approach. In this implementation will be creating a server node after model a classifier. The training is same set with 50 samples for each terrain. The server will be waiting for a request from another node, which is in this case segment data. The segment data gather data stream from the optoforce sensor. The method to collecting interesting data is described in \ref{subseq:segmentation}. After a step is extracted from sensor, it will then be passed to the server. The server will receive the data and start to preprocess the data. It will extracted features, select features and scale accordingly to the training samples. The last step will be to predict the feature vector. The result is what terrain it is on. However, in this case the Python provide a probability function on SVM, which is used. In the documentation the probability might give wrong probability on very small data set. However, the data set is considered as not very small data set, and it is interesting to look at probability when it predict. After given a result, it will be waiting for new partitioned from segment data. 


\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[scale=0.7,transform shape]
	
	% Draw diagram elements
	%  \path \io{1}{Raw data};
	\path \io{1}{Read file};
	%  \path (p1.south)+(0,-1.5) \etape{2}{Extract steps};
	\path (p1.south)+(0.0,-1.5) \etape{2}{Extract features};
	\path (p2.south)+(0.0,-1.5) \etape{3}{Feature selection};
	
	\path (p3.south)+(0.0,-1.5) \etape{4}{Scaling};
	\path (p4.south)+(0.0,-1.5) \etape{12}{Training the model};
	
	\path (p12.south)+(0,-1.5) \etape{5}{Create server};
	\path (p5.south)+(0,-1.5) \etape{6}{Waiting for request};
	\path (p6.south)+(0,-2.5) \dec{7}{Request?};
	\path (p7.south)+(0,-1.5) \etape{8}{Preprocess data};
	\path (p8.south)+(0,-1.5) \etape{9}{Predict};
	
	
	%\path (request?.south)+(0,-1.5) \etape{7}{Predicted};
	
	\path (p5.west)+(8.5,0) \etape{10}{Raw data stream};
	\path (p10.south)+(0,-1.5) \etape{11}{Segment data};


	


	% Draw arrows between elements
	\path [line] (p1.south) -- node [above] {} (p2);
	\path [line] (p2.south) -- node [above] {} (p3);
	\path [line] (p3.south) -- node [above] {} (p4);
	\path [line] (p4.south) -- node [above] {} (p12);
	\path [line] (p12.south) -- node [above] {} (p5);
	\path [line] (p5.south) -- node [above] {} (p6);
	\path [line] (p6.south) -- node [above] {} (p7);
	\path [line] (p7.south) -- node [right] {Yes} (p8);
	\path [line] (p7.west) -- ++(-2,0) |- node [above] {No} (p6);
	\path [line] (p8.south) -- node [above] {} (p9);
	\path [line] (p9.east) -| node [above] {} (p11);
	
	\path [line] (p10.south) -- node [above] {} (p11);
	\path [line] (p11.west) -- node [above] {Data sample} (p6);
%	\path [line] (p11.south) -- node [above] {} (p4);

	
%	\path [line] (p5.south) -- node [above] {} (p6);

%	\path [line] (p4.south) -- node [right] {} (p9);

%	\path [line,dashed] (p6) -- node [above]{Data sample} (p9);
%	\path [line] (p9.south) -- node [right] {} (p7);
	
	\end{tikzpicture}
	
	\caption{Figure showing the real-time implementation} \label{fig:realtime}
\end{figure}
\FloatBarrier


\clearpage
\subsection{Floor to carpet}
The data stream is shown in figure \ref{fig:gulvet4teppegraf} and the table \ref{tab:Gulvet4teppe} show probability of the terrains for each step. In this experiment the robot walked four step on floor and the rest on carpet. The accuracy of predicting correct is 88.9\%. However, looking how certain the classifier to predict correct is lower. Fifth step is the transition and as it can be seen it is confused. It is worth noticing that at fourth step the carpet has almost same probability as the floor. The soft mat and hard mat has small probability and is more likely not to be predicted.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/Gulvet4Teppe2}
    \caption{Figure showing data stream from sensor when the robot walked from floor to carpet.}
    \label{fig:gulvet4teppegraf}
\end{figure}


\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllllllll@{}}
\toprule
\rowcolor[HTML]{FFFFC7} 
\textbf{Step} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} & \textbf{9} \\ \midrule
Floor & \cellcolor[HTML]{34FF34}0.782 & \cellcolor[HTML]{34FF34}0.680 & \cellcolor[HTML]{34FF34}0.747 & \cellcolor[HTML]{34FF34}0.561 & \cellcolor[HTML]{FD6864}0.564 & 0.282 & 0.206 & 0.252 & 0.282 \\
Carpet & 0.105 & 0.289 & 0.162 & 0.425 & \cellcolor[HTML]{F8FF00}0.353 & \cellcolor[HTML]{34FF34}0.704 & \cellcolor[HTML]{34FF34}0.730 & \cellcolor[HTML]{34FF34}0.573 & \cellcolor[HTML]{34FF34}0.599 \\
Soft mat & 0.008 & 0.009 & 0.010 & 0.008 & 0.010 & 0.005 & 0.009 & 0.009 & 0.015 \\
Hard mat & 0.104 & 0.022 & 0.081 & 0.007 & 0.073 & 0.010 & 0.055 & 0.166 & 0.104 \\ \bottomrule
\end{tabular}%
}
\caption{The table showing probability of each terrain per step from floor to carpet. Marked green represent correct prediction and correct terrain, red represent wrong prediction and yellow is the correct prediction if it got wrong.}
\label{tab:Gulvet4teppe}
\end{table}
\FloatBarrier

\clearpage
\subsection{Hard mat to floor} \label{subsec:hmf}
The data is shown in figure \ref{fig:mb3Gulvet} and the table \ref{tab:mb3Gulvet} show how the probability of each step, walking from hard mat to floor. The overall accuracy of predicting correct is 50\%. It can be seen that the first two step it is clearly what terrain it is on. While the third step start to be confused between hard mat and carpet. When it is on floor it rather predicting the floor.



\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/MB3_3_Gulvet}
    \caption{Figure showing data stream from sensor when the robot walked from hard mat to floor}
    \label{fig:mb3Gulvet}
\end{figure}


\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllll@{}}
\toprule
\rowcolor[HTML]{FFFFC7} 
\textbf{Step} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} \\ \midrule
Floor & 0.006 & 0.008 & 0.172 & \cellcolor[HTML]{F8FF00}0.263 & \cellcolor[HTML]{F8FF00}0.141 & \cellcolor[HTML]{F8FF00}0.078 \\
Carpet & 0.008 & 0.073 & 0.375 & \cellcolor[HTML]{FD6864}0.641 & \cellcolor[HTML]{FD6864}0.615 & \cellcolor[HTML]{FD6864}0.822 \\
Soft mat & 0.006 & 0.004 & 0.008 & 0.023 & 0.019 & 0.014 \\
Hard mat & \cellcolor[HTML]{34FF34}0.980 & \cellcolor[HTML]{34FF34}0.915 & \cellcolor[HTML]{34FF34}0.444 & 0.073 & 0.225 & 0.085 \\ \bottomrule
\end{tabular}%
}
\caption{The table showing probability of each terrain per step walking from hard mat to floor. Marked green represent correct prediction and correct terrain, red represent wrong prediction and yellow is the correct prediction if it got wrong.}
\label{tab:mb3Gulvet}
\end{table}

\FloatBarrier
\clearpage
\subsection{Hard mat to soft mat} \label{sec:hmssm}
The data is shown in figure \ref{fig:hardmatSoftMat} and the table \ref{hardmatSoftMat} show how the probability of each step in transition from hard mat to soft mat. As seen on the figure \ref{fig:hardmatSoftMat} there is a clearly difference between walking on hard mat and soft mat. Hard mat has a higher force in every direction. However, there are some uncertain of prediction on the first, third and sixth step, where it has a probability under 54\%. 


\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/MB3MM}
    \caption{Figure showing data stream from sensor when the robot walked from hard mat to soft mat.}
    \label{fig:hardmatSoftMat}
\end{figure}

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllll@{}}
\toprule
\rowcolor[HTML]{FFFFC7} 
\textbf{Step} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & 7 & 8 \\ \midrule
Floor & 0.329 & 0.015 & 0.081 & 0.059 & 0.022 & 0.115 & 0.059 & 0.048 \\
Carpet & 0.105 & 0.045 & 0.105 & 0.041 & 0.015 & 0.095 & 0.037 & 0.033 \\
Soft mat & 0.023 & 0.006 & 0.284 & \cellcolor[HTML]{34FF34}0.759 & \cellcolor[HTML]{34FF34}0.923 & \cellcolor[HTML]{34FF34}0.477 & \cellcolor[HTML]{34FF34}0.816 & \cellcolor[HTML]{34FF34}0.834 \\
Hard mat & \cellcolor[HTML]{34FF34}0.542 & \cellcolor[HTML]{34FF34}0.935 & \cellcolor[HTML]{34FF34}0.529 & 0.142 & 0.040 & 0.313 & 0.088 & 0.085 \\ \bottomrule
\end{tabular}%
}
\caption{The table showing probability of each terrain per step walking from hard mat to soft mat. Marked green represent correct prediction and correct terrain, red represent wrong prediction and yellow is the correct prediction if it got wrong.}
\label{hardmatSoftMat}
\end{table}
\FloatBarrier
\clearpage

\subsection{Soft mat to hard mat}
The data stream is shown in figure \ref{fig:MM_4_Resten_BGraf} and the table \ref{MM4MB} show probability of the terrains for each step. Again, the accuracy of predicting correct is 100\%. In this experiment the classifier is able without any problem. However prediction at beginning (first step), and the step right before new terrain (fourth step), has probability under 53\%.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/MM_4Resten_MB}
    \caption{Figure showing data stream from sensor when the robot walked from soft mat to hard mat.}
    \label{fig:MM_4_Resten_BGraf}
\end{figure}

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllllll@{}}
\toprule
\rowcolor[HTML]{FFFFC7} 
\textbf{Step} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & 7 \\ \midrule
Floor & 0.099 & 0.019 & 0.018 & 0.138 & 0.021 & 0.008 & 0.038 \\
Carpet & 0.065 & 0.023 & 0.017 & 0.134 & 0.050 & 0.005 & 0.022 \\
Soft mat & \cellcolor[HTML]{34FF34}0.535 & \cellcolor[HTML]{34FF34}0.871 & \cellcolor[HTML]{34FF34}0.911 & \cellcolor[HTML]{34FF34}0.384 & 0.009 & 0.009 & 0.011 \\
Hard mat & 0.300 & 0.086 & 0.054 & 0.344 & \cellcolor[HTML]{34FF34}0.921 & \cellcolor[HTML]{34FF34}0.978 & \cellcolor[HTML]{34FF34}0.930 \\ \bottomrule
\end{tabular}%
}
\caption{The table showing probability of each terrain per step walking from soft mat to hard mat. Marked green represent correct prediction and correct terrain, red represent wrong prediction and yellow is the correct prediction if it got wrong.}
\label{MM4MB}
\end{table}
\FloatBarrier
\clearpage
\subsection{Soft mat to carpet}
The data stream is shown in figure \ref{fig:softcarpet} and the table \ref{tab:softcarpet} show probability of the terrains for each step. It has predicted 7 of 8 correctly. As seen in the figure \ref{fig:softcarpet}, there is a large variation from walking soft mat to carpet. On small soft mat the amplitude is significant smaller than carpet. At the fifth step is when the robot walked from the old terrain to the new one, and the probability of carpet is approximately 66.7\%. However the second highest has a probability of 21.6\%, which it clear what terrain it is. Regarding sixth step, the classifier has a wrong prediction between carpet and hard mat. There is a high probability of hard hard mat. A few factors which might cause that, is looking to the figure \ref{fig:softcarpet}. The shape y direction differ from the other after it, and so is for the amplitude.



\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/MM4Teppe2}
    \caption{Figure showing data stream from sensor when the robot walked from soft mat to carpet.}
    \label{fig:softcarpet}
\end{figure}

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllll@{}}
\toprule
\rowcolor[HTML]{FFFFC7} 
\textbf{Step} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & 7 & 8 \\ \midrule
Floor & 0.021 & 0.022 & 0.068 & 0.031 & 0.100 & 0.020 & 0.016 & 0.018 \\
Carpet & 0.017 & 0.019 & 0.049 & 0.023 & \cellcolor[HTML]{34FF34}0.667 & \cellcolor[HTML]{F8FF00}0.041 & \cellcolor[HTML]{34FF34}0.942 & \cellcolor[HTML]{34FF34}0.904 \\
Soft mat & \cellcolor[HTML]{34FF34}0.909 & \cellcolor[HTML]{34FF34}0.914 & \cellcolor[HTML]{34FF34}0.762 & \cellcolor[HTML]{34FF34}0.891 & 0.017 & 0.007 & 0.006 & 0.006 \\
Hard mat & 0.054 & 0.045 & 0.121 & 0.055 & 0.216 & \cellcolor[HTML]{FD6864}0.933 & 0.037 & 0.072 \\ \bottomrule
\end{tabular}%
}
\caption{The table showing probability of each terrain per step walking from soft mat to carpet. Marked green represent correct prediction and correct terrain, red represent wrong prediction and yellow is the correct prediction if it got wrong.}
\label{tab:softcarpet}
\end{table}
\FloatBarrier
\subsection{Summary}
In this experiment five different transition between two terrains. A common characteristic is that the probability decrease particular on the transition step. It predict correct when the terrain has a huge difference to the other such as soft mat. While transition between more similar terrain has a wrong prediction at the transition. The first step has tend to either have relative high probability approximately 90\% or low probability approximately 54\%.


\section{Prediction on other sensor}
The classification has been based on only one sensor on front left foot, thus it will be interesting to see whether it is possible to use the currently training set to classify accurately on front right foot. If it achieve a high accuracy might indicate that one the both feet on the front can be using the same training set instead of separately which is more convenient.

\section{Result} 

\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}lllll@{}}
			\toprule
			\textbf{Terrain} & \textbf{Floor} & \textbf{Carpet} & \textbf{Soft mat} & \textbf{Hard mat} \\ \midrule
			\textbf{Floor} & \cellcolor[HTML]{FFFFC7}29 & 1 & 0 & 0 \\
			\textbf{Carpet} & 3 & \cellcolor[HTML]{FFFFC7}27 & 0 & 0 \\
			\textbf{Soft mat} & 0 & 0 & \cellcolor[HTML]{FFFFC7}30 & 0 \\
			\textbf{Hard mat} & 2 & 13 & 0 & \cellcolor[HTML]{FFFFC7}16 \\ \midrule
			\textbf{Precision} & 96.7\% & 90\% & 100\% & 53.3\% \\
			\textbf{Recall} & 85.3\% & 65.9\% & 100\% & 100\% \\
			\textbf{F-score} & 90.6\% & 76.1\% & 100\% & 69.5\% \\ \midrule
			\textbf{Accuracy} & \multicolumn{4}{c}{84.3\%} \\ \bottomrule
		\end{tabular}%
	}
	\caption{My caption}
	\label{my-label}
\end{table}
\FloatBarrier
\begin{comment}

\section{Less traning samples}
As mentioned section \ref{subseq:validation}, mostly study k equally two or ten and still has a high accuracy. Thus, it will be interesting to see the performance of the classifier with a smaller set of training set by setting k to two or ten.

\subsection{K = 2}
\begin{table}[h]
	\centering
	\begin{tabular}{llllll}
		\hline
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cline{3-6} 
		&  & \multicolumn{1}{l|}{Floor} & \multicolumn{1}{l|}{Carpet} & \multicolumn{1}{l|}{Soft mat} & Hard mat \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{92\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{4} & \multicolumn{1}{l|}{46} & \multicolumn{1}{l|}{0} & 1 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{9} & \multicolumn{1}{l|}{0} & 39 \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{87.5\%}} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{44} & \multicolumn{1}{l|}{0} & 1 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{15} & \multicolumn{1}{l|}{0} & 34 \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{89\%}} & \multicolumn{1}{l|}{37} & \multicolumn{1}{l|}{13} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{0} & 41
	\end{tabular}
	\caption{My caption}
	\label{my-label}
\end{table}
\FloatBarrier

\subsection{K = 10}
\begin{table}[h]
	\centering
	\begin{tabular}{llllll}
		\hline
		\multirow{2}{*}{\textbf{Run}} & \multirow{2}{*}{\textbf{Accuracy}} & \multicolumn{4}{c}{\textbf{Confusion matrix}} \\ \cline{3-6} 
		&  & \multicolumn{1}{l|}{\textbf{Floor}} & \multicolumn{1}{l|}{\textbf{Carpet}} & \multicolumn{1}{l|}{\textbf{Soft mat}} & \textbf{Hard mat} \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{1}} & \multicolumn{1}{l|}{\multirow{4}{*}{95\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{48} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{6} & \multicolumn{1}{l|}{0} & 42 \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{2}} & \multicolumn{1}{l|}{\multirow{4}{*}{93\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{8} & \multicolumn{1}{l|}{0} & 40 \\ \hline
		\multicolumn{1}{l|}{\multirow{4}{*}{3}} & \multicolumn{1}{l|}{\multirow{4}{*}{94\%}} & \multicolumn{1}{l|}{50} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{47} & \multicolumn{1}{l|}{0} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{50} & 0 \\ \cline{3-6} 
		\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{7} & \multicolumn{1}{l|}{0} & 41
	\end{tabular}
	\caption{My caption}
	\label{my-label}
\end{table}
\FloatBarrier
\end{comment}

\chapter{Discussion}

\section{Five classifier prediction on unseen data}
It is shown that the many classifiers has decreased performance when it come to predicting unseen data. As seen in section \ref{seq:crossunseen}, the neural network and decision tree does not show adequate performance. A reason could be that the classifier is overfitted and not able to generalize the data. Note that those classifiers of raw data sequences, and the method of achieving fixed length by decimate data described in section \ref{subseq:FixLength} might been affecting the performance. In this approach it is considered that data at start and the end of sequence is less important. However, the longer the sequence is, the more data must be removed from the feature vector and has a risk of removing important features. Another weakness of using raw data is the risk of learning with noises. Learning with noises might cause of not generalization the model and achieve a poor performance. However, noises are inherent in real world measurement, thus by discarding the noises might also give a poor result. Note each classifier use their default values which also affect the performance, especially neural network. The neural network is a complex classifier with many parameter that need to be adjusted such as size of hidden layers. Amount of hidden layers and hidden nodes provide significant improvement in their performance.  
\\
\\
Regarding a common confusion on hard mat, for each of classifier tend to predict it as carpet, while the soft mat has a high probability. As seen on previous chapter \ref{ch:implementation} in figures \ref{fig:meanxyz} and \ref{fig:fftxyz}, the hard mat and carpet has the most similar characteristic and is most likely to be confused.
\\
\\
Regarding SVM, the results has not been change during each run. That indicate that the good features is kept and able to distinguish between each terrain. However, there is still a small confusion between floor, carpet and hard mat. 
\\
\\
Regarding different result on each run may indicate some training samples are important than other.

\section{Transition between terrains}
The result achieved in transition between terrains, done in section \ref{sec:realtime}, indicates that the classifier is able to identify terrains even with minor differences in their properties. By adding each step and divide by total, the overall accuracy is  86.8\%. Misclassification is mostly cause of transition between hard mat to floor, seen in table \ref{sec:hmssm}. After traversing from hard mat to carpet, the classifier tend to predict floor. Looking on estimation of unseen data in table \ref{svmexp}, show a that the carpet tend to have small misclassification to floor. But, as mentioned in section \ref{sec:realtime}, the robot tend to not walking straight, which might cause misclassification. All of the training samples has been gathered when the robot walked straight. Thus, since the sensor is highly sensitive it might be affected when it walks toward right or left.
\\
\\
Having training samples where the robot traversing straight through each of one terrain have shown some significant appreciable in their performance. Observations on steps before crossing to new terrain has a less probability of predicting correct. A feasible method to prevent this, is to have training samples where it traverse through different terrains. However, misclassifying terrain when it cross should not be important when it is able to identify terrains after few step.    
\\
\\
Is also seen that in the beginning the probability of correct terrain is also typically low. It might indicate that the first step has a particular behavior, as the in the middle the robot got more stable, thus more training data on the first step to achieved higher probability on first step. It is shown that the sensor is capable to distinguish minor differently terrain, even the probability is low. Soft mat has a low start.



\section{Conclusion}



\subsection{Compared to earlier work}
Looking of early similar approaches on table \ref{table:compareEarly}, the thesis approach has achieved reliable result by using the optical force sensor....  
\begin{table}[h]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}lllll@{}}
			\toprule
			\textbf{Approach} & \textbf{Sensor used} & \textbf{Classifier} & \textbf{\begin{tabular}[c]{@{}l@{}}Number of\\ terrains\end{tabular}} & \textbf{Accuracy} \\ \midrule
			\multirow{3}{*}{Hoepflinger el at. \cite{5509309}} & \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Force sensing\\ Joint motor currents\end{tabular}} & \multirow{3}{*}{Adaboost} & \multirow{3}{*}{4} & \multirow{3}{*}{73.3\%} \\
			&  &  &  &  \\
			&  &  &  &  \\
			\multirow{3}{*}{Kim el at. \cite{5602459}} & \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Ground reaction force \\ Torque sensors\end{tabular}} & \multirow{3}{*}{SVM} & \multirow{3}{*}{4} & \multirow{3}{*}{78.75\%} \\
			&  &  &  &  \\
			&  &  &  &  \\
			\multirow{3}{*}{Kertész \cite{6849778}} & \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Accelerometer\\ Paw sensor\end{tabular}} & \multirow{3}{*}{Naive Bayes} & \multirow{3}{*}{5} & \multirow{3}{*}{90.9\%} \\
			&  &  &  &  \\
			&  &  &  &  \\
			\multirow{2}{*}{Weiss el at. \cite{4059113}} & \multirow{2}{*}{Vibration} & \multirow{2}{*}{SVM} & \multirow{2}{*}{7} & \multirow{2}{*}{91.7\%} \\
			&  &  &  &  \\
			\multirow{2}{*}{Degrave el at. \cite{6784609}} & \multirow{2}{*}{Tactile sensor} & \multirow{2}{*}{Reservoir Computing} & \multirow{2}{*}{5} & \multirow{2}{*}{93.8\%} \\
			&  &  &  &  \\
			\multirow{2}{*}{Giguere and Dudek \cite{5752869}} & \multirow{2}{*}{Tactile probe} & \multirow{2}{*}{Neural network} & \multirow{2}{*}{5} & \multirow{2}{*}{94.3\%} \\
			&  &  &  &  \\
			\multirow{2}{*}{Thesis approach} & \multirow{2}{*}{Optical force sensor} & \multirow{2}{*}{SVM} & \multirow{2}{*}{4} & \multirow{2}{*}{95.2\%} \\
			&  &  &  &  \\ \bottomrule
		\end{tabular}%
	}
	\caption{Table showing a comparison between thesis approach with other approaches. Result of this approach is the mean of the accuracy from LOOCV on unseen data.}
	\label{table:compareEarly}
\end{table}
\FloatBarrier


\subsection{Future work}
Every classifier has parameters that can be optimized. Using default values is more unlikely that this is suitable for terrain classification. Although, in the first two experiment has shown a reliable performance of classifiers, however it becomes unreliable when it comes to predicting unseen data. It could be that more training samples is needed. However, choosing a correct set of hyper parameters might increase its performance. Thus, having hyper parameter optimization could be further research, to see if there are other classifiers achieve a better performance than currently SVM.
\\
\\
The classifier is based on the features from contact force. However, features of terrain itself such as hardness and friction are not analyzed directly. It might be hidden inside the classifier and could be addressed in future work. 
\\
\\
The terrains in this thesis has only been experimented with flat terrain. It will be interesting to include more rough surface or other type. By adding more terrains it will also be interesting to fusion more sensor to achieve a higher reliability. Other type of sensor could be used such as body motion of the robot might provide more information of the terrain.  
\\
\\
Unsupervised has been addressed to few authors.

other features extraction.
Ikke decimate - kan miste viktige features
\\
\\
The learning is based on each step, maybe collect data from more than one step.
\\
\\
Oter experiments
\\
\\
%http://www2.ift.ulaval.ca/~pgiguere/terrainID.html

%Optical force (Legged Robots)
%https://link.springer.com/referenceworkentry/10.1007/978-3-540-30301-5_17

%An Overview of Legged Robots

\backmatter{}
\bibliography{bib}
\bibliographystyle{ieeetr}
\end{document}
